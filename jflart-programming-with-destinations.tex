\documentclass[english]{jflart}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{minted}
\usepackage{etoolbox,xpatch}
\usepackage{ tipa }
\usepackage{float}
\usepackage[normalem]{ulem}
\usepackage[backend=biber, style=alphabetic]{biblatex}
\usepackage{newunicodechar}
\usepackage[section]{placeins}
\addbibresource{bibliography.bib}

% Numéro et année des JFLAs visées par l'article, obligatoire.
\jfla{35}{2024}

\title{Destination-passing style programming: a Haskell implementation}
% Un titre plus court, optionnel.
%\titlerunning{Du bon usage de~\texttt{jflart.cls}}

% Auteurs, liste non abrégée.
\author[1]{Thomas Bagrel}
% \author[2]{Cunégonde Martin}
% \author[2]{Odoacre Contempierre}
% Une liste d'auteurs abrégée à utiliser à l'intérieur de l'article.
\authorrunning{Bagrel}

% Affiliations des auteurs
\affil[1]{INRIA/LORIA, Vand\oe{}uvre-lès-Nancy, 54500, France}
\affil[2]{TWEAG, Paris, 75012, France}

% Une commande définie par l'utilisateur
\newcommand{\cmd}[1]{\texttt{\textbackslash {#1}}}
\newcommand{\mpar}{\text{\,\textramshorns\,}}
\newcommand{\dest}{-\prec}
\newcommand{\TODO}[1]{{\color{red}\large #1}}
\newcommand{\mnew}[1]{\colorbox{green}{#1}}
\newcommand{\mold}[1]{\colorbox{red}{#1}}
\newunicodechar{⊸}{\ensuremath{\multimap}}
\newunicodechar{→}{\ensuremath{\to}}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{;}{\textbf{\large;}}
\newunicodechar{∀}{\ensuremath{\forall}}
\makeatletter
\AtBeginEnvironment{minted}{\dontdofcolorbox}
\def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
\xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
\xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{} % see https://tex.stackexchange.com/a/401250/
\makeatother

\begin{document}

\maketitle

\begin{abstract}
Destination-passing style programming introduces destinations, which represents the address of a write-once memory cell. Those destinations can be passed around as function parameters, and thus enable the caller of a function to keep control over memory allocation: the body of the called function will just be responsible of filling that memory cell. This is especially useful in functional programming languages such as Haskell, in which the body of a function is typically responsible for allocation of the result value.

Programming with destination in Haskell is an interesting way to improve performance of critical parts of some programs, without sacrificing memory warranties. Indeed, thanks to a linearly-typed API we designed, a write-once memory cell cannot be left uninitialized before being read, and is still disposed of by the garbage collector when it is not in use anymore, eliminating the risk of uninitialized read, memory leak, or double-free errors that can arise when memory is handled manually.

With the implementation of destinations for Haskell through compact regions we provide in this article, we reach a 15-40\% improvement over memory allocation in a simple parser example, and 0-50\% improvement in run time. We also provide a few examples of programs that can be implemented in a tail-recursive fashion thanks to destinations, which is crucial for performance in strict contexts.

Safety proofs for the API are not provided in this article though, and will be the subject of a future article.
\end{abstract}

\tableofcontents{}

\section{Introduction}

Destinations bring a taste of imperative programming in a pure functional environnement when performance really matters, without breaking memory safety.

Using destinations as a way of allocating and building functional data structures can lead to better time and/or space performance for critical parts of a program, but destinations also increase expressiveness of a functional language.

\TODO{Write introduction}

%TODO: conceptuellement simple, mais beaucoup d'obstacles techniques pour rendre ça possible.
% TODO GHC where purity is enforced
% TODO Also because it has good support for linear type discipline
% TODO Linear types
% TODO Destinations
% TODO Compact regions
% TODO strict lazy haskell

\section{Motivating examples for destination-passing style programming}

Destination-passing style programming, which will be abbreviated DPS programming in the rest of the article, takes its source in the early days of imperative languages with manual memory management. In the C programming language, it's quite common for a function not to allocate memory itself for its result, but rather to receive a reference to a memory location where to write its result (often named \emph{out(put) parameter}). In that scheme, the caller of the function is both responsible for allocation and disposal of the cell in which the value will live. This is exactly what DPS programming is about: take control from the callee back to the caller about memory management.

DPS programming need a concept of reference or pointer to communicate the location of the memory cell in which the called function should write its result. In functional programming languages, these are often named \emph{destinations}, so we will use this name to refer to the address of a write-once memory cell in Haskell.

It's time to see why DPS programming can be useful even in a pure functional context such as Haskell.

\subsection{Efficient \emph{Difference list} implementation}

Linked lists are a staple of functional programming, but they aren't efficient for concatenation, especially when the concatenation calls are nested to the left.

In an imperative context, it would be quite easy to concatenate linked lists efficiently. One just have to keep both a pointer to the root and to the last \emph{cons} cell of each list. Then, to concatenate two lists, one just have to mutate the last \emph{cons} cell of the first one to point to the root of the second list.

This isn't possible to do in an immutable functional context though. Instead, \emph{Difference lists} can be used: they are structures that are fast to convert into lists ($\mathcal{O}(1)$ amortized) and tend to emulate the idea of having a mutable (here, write-once) last \emph{cons} cell. Usually, a difference list \mintinline{haskell}`[x1, ..., xn, ?]` is encoded by a function taking a last element \mintinline{haskell}`ys` of type \mintinline{haskell}`[a]` and returning \mintinline{haskell}`x1 : ... : xn : ys` (having type \mintinline{haskell}`[a]` too). \TODO{reference for difference list paper}

With such representation, concatenation is just function composition: \mintinline{haskell}`f1 <> f2 = f1 . f2`, and we have \mintinline{haskell}`mempty = id`\footnote{\mintinline{haskell}`mempty` and \mintinline{haskell}`<>` are the standard notations for the neutral element and internal operation of a monoid in Haskell}, \mintinline{haskell}`toList f = f []` and \mintinline{haskell}`fromList xs = \ys → xs ++ xs`.

In DPS, instead of encoding the concept of a write-once hole with a function, we can represent the hole as a first-class object with a \emph{destination}. A difference list now become an actual data structure in memory --- not just a pending computation --- that has two handles: one to the root of the list of type \mintinline{haskell}`[a]`, and one to the yet-to-be-filled hole in the last cons cell, represented by a destination of type \mintinline{haskell}`Dest [a]`.

With the function encoding, it isn't possible to read the list until a last element of type \mintinline{haskell}`[a]` have been supplied to complete it. With the destination representation, this constraint must persists: the actual list \mintinline{haskell}`[a]` shouldn't be readable until the accompanying destination is filled (or \emph{linearly consumed}, as we sometimes write), otherwise memory safety wouldn't be respected. This constraint is embodied by the \mintinline{haskell}`Incomplete a b` type of our destination API: \mintinline{haskell}`b` is what needs to be linearly consumed to make the \mintinline{haskell}`a` readable. Most of the time, the \mintinline{haskell}`b` side carries the destinations of the structure. A difference list is then \mintinline{haskell}`type DList a = Incomplete [a] (Dest [a])`: one should fill the \mintinline{haskell}`Dest [a]` (with a \mintinline{haskell}`[a]`) to get a readable \mintinline{haskell}`[a]`.

% TODO
% How to fill these holes?

% 1. fillLeaf + schema
% 2. fill @' + schema
% 3. fillComp + schema
% Those 3 will be useful for the implementation of ...

The implementation of operations on destination-backed difference lists are presented in table~\ref{table:impl-dlist}.
\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
data [a] -- built-in
  = []        -- nil constructor
  | (:) a [a] -- cons constructor

type DList a = Incomplete [a] (Dest [a])

alloc :: DList a

append :: DList a ⊸ a → DList a
append i x =
  i <&> \d → case fill @'(:) d of
    (dh, dt) → fillLeaf x dh ;; dt

concat :: DList a ⊸ DList a ⊸ DList a
concat i1 i2 = i1 <&> \dt1 -> fillComp i2 dt1

toList :: DList a ⊸ [a]
toList i = fromIncomplete_' (i <&> \dt → fill @'[] dt)
\end{minted}
\caption{Implementation of difference lists with destinations}
\label{table:impl-dlist}
\end{table}

\begin{figure}[t]
\includegraphics[height=22cm]{schema-dlist.pdf}
\caption{Memory behavior of difference lists backed by destinations}
\label{fig:schema-dlist}
\end{figure}

\begin{itemize}
  \item \mintinline{haskell}`alloc` returns a \mintinline{haskell}`DList a` which is exactly an \mintinline{haskell}`Incomplete [a] (Dest [a])` structure as shown at the top of part 1 of figure~\ref{fig:schema-dlist}. There is no data there yet; so the list that will be fed in the \mintinline{haskell}`Dest [a]` is exactly the list in that the \mintinline{haskell}`Incomplete` will hold. This is highly similar to the \mintinline{haskell}`id` function which represents the empty destination list in the function encoding;
  \item \mintinline{haskell}`append` fills the the hole at the end of the list \mintinline{haskell}`dl` with a new \emph{cons} cell, using \mintinline{haskell}`fill @'(:)`. The head of that cell \mintinline{haskell}`dh` is filled with the value to append using \mintinline{haskell}`fillLeaf`, and the remaining hole of the new \emph{cons} cell, represented by \mintinline{haskell}`dt :: Dest [a]`, is the hole of the resulting difference list, as shown in part 2 of figure~\ref{fig:schema-dlist};
  \item \mintinline{haskell}`concat` calls \mintinline{haskell}`fillComp`, which fills the destination of the first difference list \mintinline{haskell}`i1` with the root of the second difference list\mintinline{haskell}`i2`. The resulting \mintinline{haskell}`Incomplete` object hence has the same root as the first list, holds the elements of both lists, and has the hole of the second list at the end, as one can see in part 3 of figure~\ref{fig:schema-dlist}. Memory-wise, \mintinline{haskell}`concat` will just write the address of the root of the second list into the hole of the first one; no move is required.
  \item \mintinline{haskell}`toList` completes the incomplete structure by plugging \emph{nil} into its hole with \mintinline{haskell}`fill @'[]` and removes the \mintinline{haskell}`Incomplete` wrapper which is no longer useful, as shown in part 4 of figure~\ref{fig:schema-dlist}.
\end{itemize}

This simplified API for difference lists still lacks some linearity requirements to make it write-once/immutable. In particular, the result of \mintinline{haskell}`alloc` should be used linearly but this isn't enforced by this API, and as a result, one could fill the embedded destination twice. Linearity concerns will be addressed in subsection~\ref{ssec:api-linearity}.

That being said, thanks to destination-style programming, not only we can express programs and functions whose implementation is closer to their intended memory behaviour (here, implementing data structures with holes), but we can also get important performance improvements too. \TODO{one sentence about the benchmark results compared to the function encoding}

% TODO: remove clearpage
\clearpage{}

\subsection{Breadth-first tree traversal}\label{ssec:bf-tree-traversal}

The idea of functional data structure with write-once holes is not new. In 1998, Minamide already proposed in~\cite{minamide_functional_1998} a variant of lambda calculus with support for \emph{hole abstractions}, which can be represented in memory by an incomplete structure with one hole and can be composed efficiently with each other (as with \mintinline{haskell}`fillComp` above). With such framework, it is fully possible to implement destination-backed difference lists, as we developed in the previous section.

However, in Minamide's work, there is no concept of destination: the hole in a structure can only be filled if one has the structure itself at hand. On the other hand, our paper introduces destinations, which are a way to interact with a hole remotely, even when one doesn't have a handle to the associated data structure. Because destination are treated as first-class objects, they can be passed around or stored in collections or other structure. Being able not only to represent data structures with holes, but also manipulate references to these holes as first-class objects while preserving memory safety, is the major step forward that this paper presents.

The fact that destinations can be stored in arbitrary data structures opens the way for more natural and efficient implementations of some functional data structure algorithms, for example breadth-first tree traversal, which isn't easy to implement in a standard immutable setting.

In breadth-first tree traversal (with effects), the order in which effects should be sequenced is completely different than the natural order of traversal of the tree. As a result, many tricks should be employed to reconciliate those two realities. Even the most elegant solutions such as \cite{gibbons_phases_2023} often involve several traversals of the tree, or the construction of additional cost-heavy structures.

With storable destinations in our toolbelt, we can implement a solution that is both easy to write and efficient, doing only a single traversal pass on the original tree. The main idea is to keep a queue of pairs, whose first component is the next node from the input tree to process, and the second is a destination referring to the location in the output tree where to write the result of processing that node. Functional structures with holes make it possible to let some parts of the tree "unfinished" for some time, and to come back at them later when it's their turn to be processed. And storing destinations which refer to these holes in a queue allows the effects to be applied in a breadth-first order so that the tree can be built in one pass. The implementation is provided in table~\ref{table:impl-bfs-tree-traversal}.

\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
data Tree a = Nil | Node a (Tree a) (Tree a)

mapAccumBFS :: ∀ a b s. (s → a → (s, b)) → s → Tree a → (Tree b, s)
mapAccumBFS f s0 tree =
  fromIncomplete' (
    alloc <&> \dtree → go s0 (singleton (Ur tree, dtree)))
  where
    go :: s → Queue (Ur (Tree a), Dest (Tree b)) ⊸ Ur s
    go s q = case dequeue q of
      Nothing → Ur s
      Just ((utree, dtree), q') → case utree of
        Ur Nil → fill @'Nil dtree ;; go s q'
        Ur (Node x tl tr) → case fill @'Node dtree of
          (dr, dtl, dtr) →
            let q'' = q' `enqueue` (Ur tl, dtl) `enqueue` (Ur tr, dtr)
                (s', r) = f s x
              in fillLeaf r dr ;; go s' q''
\end{minted}
\caption{Implementation of breadth-first tree traversal with destinations}
\label{table:impl-bfs-tree-traversal}
\end{table}

One can note that the signature of \mintinline{haskell}`mapAccumBFS` doesn't involve linear types. They are only put into use in the implementation of the \mintinline{haskell}`go` sub-function, as a way to ensure memory safety when using destinations. When \mintinline{haskell}`go` is first called, its argument are the initial state \mintinline{haskell}`s0` and a single-element queue containing a pair of the root of the input tree and a destination for the root of the output tree. Then, during the recursive calls to \mintinline{haskell}`go`, the queue is updated, and linearity enforces the fact that every destination ever put in the queue is eventually filled at some point, which guarantees that the output tree is complete after the function has run, and thus can be made readable.

Because the state-transforming function \mintinline{haskell}`s → a → (s, b)` is non-linear, the leaves of the original tree (that are stored together with destinations in the queue) won't be consumed in a linear fashion. However, as we said, destinations must be all consumed linearly, and for that to hold, their container must be consumed linearly too. So we need a trick to indicate that one sub-part of the queue is allowed to be consumed non-linearly while the rest of the structure will appeared to be consumed linearly.

This is exactly the role that the \mintinline{haskell}`Ur` wrapper plays. A \mintinline{haskell}`Ur a` will appear to be consumed linearly even if its inner value of type \mintinline{haskell}`a` is consumed non-linearly. But only values coming from a non-linear source can be put wrapped in \mintinline{haskell}`Ur`. More precisely, \mintinline{haskell}`Ur` delimitates areas for non-linear values inside structures that are meant to be handled linearly, and only values already wrapped in \mintinline{haskell}`Ur` or coming from the left of a non-linear function arrow \mintinline{haskell}`→` can be put in another \mintinline{haskell}`Ur`. Destinations always appear on the left of linear function arrows \mintinline{haskell}`⊸`, so they couldn't be wrapped in \mintinline{haskell}`Ur` in an attempt to escape the API safety.

With this example, we show how destinations can be used even in a non-linear setting in order to improve the expressiveness of the base language. This more natural and less convoluted implementation of breadth-first traversal also presents great performance gains compared to other functional implementations. \TODO{Insert benchmark}

\subsection{Deserializing a large data tree: impact on garbage collection}

Deserialization is a very common task in application development, and can become a crucial part of the program performance-wise, when the program in question is meant to be fed with large chunks of serialized data.

More importantly, when a large file is deserialized into a tree of heap objects in a garbage-collected language, the presence of the tree in the heap will dramatically increase the time taken by each garbage collection cycle, as the garbage collector (GC) will have to go through every path in the tree to check whether or not each node is alive. However, it is very common for the all the tree's nodes to stay alive for almost the same duration, and to become unused by the program roughly at the same time. Hence, the high frequency at which the GC runs is quite unadapted for that use case, and the program's performance will be hampered.

As a result, it can be highly desirable to consider the large data tree as a single heap object with a single lifetime for all its nodes. If the tree is stored in a delimited memory area (with a start address and end address known by the GC), it becomes easy for the GC to check whether there is an object that reference a part of the tree just by checking the boundaries of the area in which the tree lives. Then the tree can be discarded when there is no reference pointing to its associated memory area. Using this technique, that has first been implemented for haskell in~\cite{yang_efficient_2015} under the name of \emph{compact regions}, some nodes will stay in memory for a bit longer than they should in exchange for huge garbage collection saving, as the GC no longer have to traverse the tree at all. In a way, compact regions allows for an efficient longer-lived memory storage solution compared to the garbage-collected heap which works very well for data that will become unused after one or two GC cycles.

Compact regions are supported by GHC (the main Haskell compiler), but to this day there is no way to directly deserialize data into a compact region. Instead, the deserialization will first create a data structure in the garbage-collected heap, which can then be copied into the compact region (and removed from the garbage-collected heap by the next GC cycle). This is still useful in the long run for a program, because the GC will only go through the tree one more time after it has been copied to the compact region (during which it will detect that all nodes are no longer used), and never after that. Nonetheless, it would be even better to directly deserialize the input data into a compact region, and eliminate the unnecessary copy and GC load that happen because a couple of GC cycles will take place during deserialization itself (especially if the input data is large).

As it will be detailed in section~\ref{sec:implementation}, compact regions have been chosen to back the implementation of DPS in Haskell, mostly because they provide more freedom to do low-level memory operations without interfering with the GC. Because of that, the current implementation of destination-passing style Haskell gives a way to build structures directly into compact regions, bypassing the garbage-collected heap entirely, as we were looking to do! Compact regions also enforce strictness (unlike Haskell's default laziness), which is quite useful for a parser, as one would probably like to catch all potential errors in the input document at the beginning of the execution.

\medskip

We'll show here how a simple parser for S-expressions can be transformed into one using destinations for greater performance. S-expressions are parenthesized lists whose elements are just separated by spaces. These elements can be of several types: int, string, symbol (a textual token, with no quotes around it, unlike a string), or a list of other S-expressions.

Parsing a S-expression can be done concisely with three mutually recursive functions:
\begin{itemize}
  \item \mintinline{haskell}`parseSExpr` scans the next character, and either dispatches to \mintinline{haskell}`parseSList` if it encounters an opening parenthesis, or to \mintinline{haskell}`parseSString` if it encounters an opening quote, or eventually parses the string into a number or symbol;
  \item \mintinline{haskell}`parseSList` calls \mintinline{haskell}`parseSExpr` to parse the next token, and then calls itself again until reaching a closing parenthesis, accumulating the parsed elements along the way;
  \item \mintinline{haskell}`parseSString` scans the input character by character and accumulates them until reaching a closing quote (taking escape sequences into consideration).
\end{itemize}

Only \mintinline{haskell}`parseSList` implementation will be presented here as it is enough for our purpose, but the full implementation of both the naive and destination-based versions can be found in annex~\ref{ann:parse-s-expr}

{\small
\begin{minted}[linenos]{haskell}
parseSList :: ByteString → Int → [SExpr] → Either Error SExpr
parseSList bs i acc = case bs !? i of
  Nothing → Left (UnexpectedEOFSList i)
  Just c → if
    | c == ')' → Right (SList i (reverse acc))
    | isSpace c → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        Left err → Left err
        Right child → parseSList bs (endPos child + 1) (child : acc)
\end{minted}
}

This tail-recursive implementation above is quite standard: the accumulator \mintinline{haskell}`acc` collects the nodes that are returned by the call to \mintinline{haskell}`parseSExpr` in the reverse order (because it's the natural building order for a linked list without destinations). When the end of the SList is reached (line 5), the accumulator is reversed and stored in the \mintinline{haskell}`SList` constructor, before being returned.

We will see that destinations can bring very significative performance gains with only very little stylistic changes in the code. Accumulators of tail-recursive functions just have to be changed into destinations. Instead of writing elements into a list that will be reversed at the end as we did before, the program in the destination style will directly write the elements into their final location:

{\small
\begin{minted}[linenos,escapeinside=°°]{haskell}
parseSListDPS :: ByteString → Int → Dest [SExpr] ⊸ Either Error Int
parseSListDPS bs i d = case bs !? i of
  Nothing → °\mnew{fill @'[] d}° ;; Left (UnexpectedEOFSList i)
  Just c → if
    | c == ')' → °\mnew{fill @'[] d}° ;; Right i
    | isSpace c → parseSListDPS bs (i + 1) d
    | otherwise →
        let !(dh, dt) = °\mnew{fill @'(:) d}°
        in case parseSExprDPS bs i °\mnew{dh}° of
              Left err → fill @'[] dt ;; Left err
              Right endPos → parseSListDPS bs (endPos + 1) °\mnew{dt}°
\end{minted}
}

Let's see what changed compared to the naive implementation:

\begin{itemize}
  \item even for error cases, we are forced to consume the destination that we receive as an argument, hence we write some sensible default data to it (see line 3);
  \item the \mintinline{haskell}`SExpr` value resulting from the call of \mintinline{haskell}`parseSExprDPS` is not collected by \mintinline{haskell}`parseSListDPS`; but instead written directly into its final location by \mintinline{haskell}`parseSExprDPS` through the passing and filling of destination \mintinline{haskell}`dh` (see line 9);
  \item adding an element of type \mintinline{haskell}`SExpr` to the accumulator \mintinline{haskell}`[SExpr]` is replaced with adding a new cons cell with \mintinline{haskell}`fill @'(:)` into the hole represented by \mintinline{haskell}`Dest [SExpr]`, writing an element to the ``head'' destination, and then doing a recursive call with the ``tail'' destination passed as an argument (which has type \mintinline{haskell}`Dest [SExpr]` again);
  \item instead of reversing and returning the accumulator at the end of the processing, it is enough to complete the list by writing a nil element to the tail destination (with \mintinline{haskell}`fill @'[]`) (see line 5).
\end{itemize}

It is important to note that destinations allow to reverse the natural order in which a structure is built. For a list, the natural operation in functional programming languages is \emph{prepend}/\mintinline{haskell}`(:)`, which adds an element at the front of an existing list (bottom-up approach). Thanks to destinations, it's possible to build a list starting from an element which will stay at the head of the it, and add new elements towards the tail of the list (top-down approach, with \emph{append}/\mintinline{haskell}`fill @'(:)`). Of course, it is possible to mix both approaches, thanks to \mintinline{haskell}`fillComp`/\mintinline{haskell}`fillLeaf`.

Thanks to that new implementation which is barely longer (in terms of lines of code) than the naive one, the program runs almost twice as fast, mostly because garbage-collection time goes to almost zero. The detailed benchmark is available in subsection~\ref{ssec:benchmark-parser}.

% TODO: parler de map TR ?

\section{API Design}\label{sec:api}

\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt]{haskell}
data Token
consume   ::      Token ⊸ ()
dup2      ::      Token ⊸ (Token, Token)
withToken :: ∀ a. (Token ⊸ Ur a) ⊸ Ur a

data Incomplete a b
fmap                :: ∀ a b c. (b ⊸ c) ⊸ Incomplete a b ⊸ Incomplete b c
alloc               :: ∀ a.     Token ⊸ Incomplete a (Dest a)
intoIncomplete      :: ∀ a.     Token ⊸ a → Incomplete a ()
fromIncomplete_     :: ∀ a.     Incomplete a () ⊸ Ur a
fromIncomplete      :: ∀ a b.   Incomplete a (Ur b) ⊸ Ur (a, b)
-- fromIncomplete_' :: ∀ a.     Incomplete a () ⊸ a
-- fromIncomplete'  :: ∀ a b.   Incomplete a (Ur b) ⊸ (a, b)

data Dest a
type family DestsOf lCtor a -- returns dests associated to fields of constructor
fill     :: ∀ lCtor a. Dest a → DestsOf lCtor a
fillComp :: ∀ a b.     Incomplete a b ⊸ Dest a ⊸ b
fillLeaf :: ∀ a.       a → Dest a ⊸ ()
\end{minted}
\caption{Destination API for Haskell}
\label{table:destination-api}
\end{table}

\subsection{The \texttt{Incomplete} type}

The main design principle behind DPS structure building is that no structure can be read before all its destinations have been filled. That way, incomplete data structures can be freely passed around and stored, but need to be completed before any pattern-matching can be made on them.

Hence we introduce a new data type \mintinline{haskell}`Incomplete a b` where \mintinline{haskell}`a` stands for the type of the structure being built, and \mintinline{haskell}`b` is the type of what needs to be linearly consumed before the structure can be read. The idea is that one can map over the \mintinline{haskell}`b` side, which will contains destinations or containers with destinations inside, until there is no destination left but just a non-linear value that can safely escape (e.g. \mintinline{haskell}`()`, an integer, or something wrapped in \mintinline{haskell}`Ur`). When destinations from the \mintinline{haskell}`b` side are consumed, the structure on the \mintinline{haskell}`a` side is built little by little in a top-down fashion, as we showed in figure~\ref{fig:schema-dlist}. And when no destination remains on the \mintinline{haskell}`b` side, the \mintinline{haskell}`a` value no longer has holes, thus is ready to be released/read.

It can be released in two ways: with \mintinline{haskell}`fromIncomplete_`, the value on the \mintinline{haskell}`b` side must be unit (\mintinline{haskell}`()`), and just the \mintinline{haskell}`a` value is returned. With \mintinline{haskell}`fromIncomplete`, the value on the \mintinline{haskell}`b` side must be of the form  \mintinline{haskell}`Ur b'`, and then the pair of type \mintinline{haskell}`(a, b')` is returned.

Because the leaves of the structure that has been built either come from non-linear sources (as \mintinline{haskell}`fillLeaf :: a → Dest a ⊸ ()` consumes its first argument non-linearly) or are made of 0-ary constructors added with \mintinline{haskell}`fill`, the whole structure can safely be used in a non-linear fashion. That's why \mintinline{haskell}`fromIncomplete_` and \mintinline{haskell}`fromIncomplete` actually wrap their result in \mintinline{haskell}`Ur`. The variants \mintinline{haskell}`fromIncomplete_'` and \mintinline{haskell}`fromIncomplete'` that have been used in the beginning of this article just drop the \mintinline{haskell}`Ur` wrapper.

The function \mintinline{haskell}`toIncomplete` takes a non-linear argument of type \mintinline{haskell}`a` and wraps it into an already-complete \mintinline{haskell}`Incomplete` with no destination on the \mintinline{haskell}`b` side. \mintinline{haskell}`fromIncomplete_' . toIncomplete token` and \mintinline{haskell}`toIncomplete token . fromIncomplete_'` might do a few unnecessary allocations, but are both equivalent to the identity function.

The whole API is presented in table~\ref{table:destination-api}.

\subsection{Ensuring write-once holes with linear types}\label{ssec:api-linearity}

Types aren't linear by themselves in Linear Haskell. Instead, functions can be made linear or not, but there is no way in direct style to state that a specific value that one own must be used exactly once. As a result, in order to enforce linearity over some resource type, one should use scope-passing style, which is a refinement over continuation-passing style. Instead of having an explicit producer of the resource type that isn't aware of the consumers for the resource, as in direct style:

{\small
\begin{minted}{haskell}
createR :: () ⊸ Resource -- no way to indicate that the result must be used once
consumeR :: Resource ⊸ ()

exampleShouldFail :: ()
exampleShouldFail =
  let r :: Resource = createR ()
   in consumeR r ;; consumeR r -- OK even though the resource r is consumed twice
\end{minted}
}

we will make the production of the resource implicit but force the consumers to become explicit:

{\small
\begin{minted}[escapeinside=°°]{haskell}
withR :: (Resource ⊸ a) ⊸ a
consumeR :: Resource ⊸ ()

exampleOk :: ()
exampleOk = withR (\r -> consumeR r)

exampleFail :: ()
exampleFail = withR (\r -> consumeR °\mold{r}° ;; consumeR °\mold{r}°) -- the callback isn't linear
\end{minted}
}

The \mintinline{haskell}`Resource` type is in positive position in the signature of \mintinline{haskell}`withR`, so that function should somehow know how to produce a \mintinline{haskell}`Resource`, but this is opaque for the user. Because the consumer of the resource must now be explicitly passed to \mintinline{haskell}`withR`, and is a function, the signature of \mintinline{haskell}`withR` can enforce that every consumer must be a linear function that will use the resource exactly once.

As a result, if \mintinline{haskell}`withR` is the only function having \mintinline{haskell}`Resource` in a positive position, then one won't be able to access a resource without using it linearly. Still, this is not enough; because \mintinline{haskell}`\x → x` is indeed a linear callback, one could use \mintinline{haskell}`withR (\x → x)` to leak a \mintinline{haskell}`Resource`, and then use it in a non-linear fashion in the outside world.

We must actually force linear consumption of the resource, not just linear use. In other terms, we must forbid the resource from appearing anywhere in the return type of the callback. To do that, we will ask the return type to be wrapped in \mintinline{haskell}`Ur`. Putting something in \mintinline{haskell}`Ur` is a non-linear operation, as we detailed in section~\ref{ssec:bf-tree-traversal}. If a value doesn't come from a non-linear source, or doesn't implement \mintinline{haskell}`Movable` --- which is a free pass to escape linearity, that is given to types such as \mintinline{haskell}`Int` or \mintinline{haskell}`()` --- then wrapping it into \mintinline{haskell}`Ur` will break linearity. We won't implement \mintinline{haskell}`Movable` for our linear resource, so any callback that would wrap the resource into \mintinline{haskell}`Ur` to escape wouldn't be linear:
{\small
\begin{minted}[escapeinside=°°]{haskell}
class Movable a where
  move :: a ⊸ Ur a
instance Movable ()
-- no instance Movable Resource

withR' :: (Resource ⊸ Ur a) ⊸ Ur a
consumeR :: Resource ⊸ ()

exampleOk' :: Ur ()
exampleOk' = withR' (\r → let u :: () = consumeR r' in move u)

exampleFail' :: Ur Resource
exampleFail' = withR' (\r → °\mold{move r}°) -- not implemented
exampleFail'' :: Ur Resource
exampleFail'' = withR' (\r → °\mold{Ur r}°) -- the callback isn't linear
\end{minted}
}

This is exactly the principle that have been used for the DPS implementation in Haskell. \mintinline{haskell}`Incomplete a b` has a \mintinline{haskell}`Control.Functor.Linear` instance to map on the \mintinline{haskell}`b` side, which forces the callback to be linear:

{\small
\begin{minted}[escapeinside=°°]{haskell}
instance Control.Functor.Linear (Incomplete a) where
  fmap :: ∀ b c. (b ⊸ c) ⊸ Incomplete a b ⊸ Incomplete b c
  fmap f (Incomplete (s, d)) = Incomplete (s, f d)
\end{minted}
}

And \mintinline{haskell}`alloc :: ∀ a. Token ⊸ Incomplete a (Dest a)` is the only function in which a \mintinline{haskell}`Dest` appears in positive position, but locked by an \mintinline{haskell}`Incomplete` (which is an opaque wrapper for the user). So destinations can only ever be accessed by mapping over an \mintinline{haskell}`Incomplete` with \mintinline{haskell}`fmap`, and cannot leak to the outside. It isn't possible either for a \mintinline{haskell}`Dest a` to be linearly consumed by filling another \mintinline{haskell}`Dest (Dest a)` with \mintinline{haskell}`fillLeaf`, as the first argument of the \mintinline{haskell}`fillLeaf` function isn't used linearly.\footnote{This is both a restriction to the potential full power of destinations, and a requirement for memory safety of this API. Allowing destinations to be stored through destinations of destination creates a lot of issues for safety of the system.}

\paragraph{Ensuring linear use of \texttt{Incomplete} objects}

We made sure that destinations inside \mintinline{haskell}`Incomplete` objects could only be used linearly, and now we need to do the same for \mintinline{haskell}`Incomplete`s themselves. For that, we introduce a new token type \mintinline{haskell}`Token`. A token can be linearly exchanged one for one with an \mintinline{haskell}`Incomplete` of any type through \mintinline{haskell}`alloc`, and can be linearly duplicated with \mintinline{haskell}`dup2` or linearly deleted with \mintinline{haskell}`consume`. However, it cannot be linearly stored in \mintinline{haskell}`Ur` as it doesn't implement \mintinline{haskell}`Movable`.

As in the example above, we just ensure that \mintinline{haskell}`withToken :: ∀ a. (Token ⊸ Ur a) ⊸ Ur a` is the only source of \mintinline{haskell}`Token`s around. Now, to produce an \mintinline{haskell}`Incomplete` with \mintinline{haskell}`alloc`, one must get a token first, so has to be in the scope of a callback which is passed to \mintinline{haskell}`withToken`. Putting either a \mintinline{haskell}`Token` or \mintinline{haskell}`Incomplete` in \mintinline{haskell}`Ur` inside the callback would then make the callback non-linear. So none of them can escape the scope as is, but a structure built from an \mintinline{haskell}`Incomplete` and finalized with \mintinline{haskell}`fromIncomplete` or \mintinline{haskell}`fromIncomplete_` would be automatically wrapped in \mintinline{haskell}`Ur`, and could safely escape the scope\footnote{This is why \mintinline{haskell}`fromIncomplete'` and \mintinline{haskell}`fromIncomplete_'` aren't that useful in the memory-safe API: the built structure would be stuck in the scope function without its \mintinline{haskell}`Ur` free pass around.}.

\subsection{Filling functions for destinations}

The last part of the API is the one in charge of actually building the structures in a top-down fashion, using layers of hollow constructors. 

To fill a hole represented by \mintinline{haskell}`Dest r a`, several functions are available:

\begin{itemize}
  \item \mintinline{haskell}`fillLeaf :: ∀ r a. (RegionContext r) ⇒ a → Dest r a ⊸ ()` \\will use a non-linear value of type \mintinline{haskell}`a` to fill the hole;
  \item \mintinline{haskell}`fillComp :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a b ⊸ Dest r a ⊸ b` \\will use an incomplete object of type \mintinline{haskell}`a` to fill the hole; and the resulting holes for the bigger structure will be the ones of that object. In other terms, \mintinline{haskell}`fillComp` composes two structures with holes together;
  \item \mintinline{haskell}`fill :: ∀ lCtor r a. Dest r a ⊸ DestsOf lCtor r a` \\takes a constructor as a type parameter (\mintinline{haskell}`lCtor`) and will write a hollow instance of that constructor into the \mintinline{haskell}`Dest r a`, returning the destinations corresponding to that constructor's fields.\\ For example, \mintinline{haskell}`fill @Just @r @(Maybe Int) :: Dest r (Maybe Int) ⊸ Dest r Int` writes a hollow \mintinline{haskell}`Just` constructor in the \mintinline{haskell}`Maybe Int` hole, and returns the \mintinline{haskell}`Dest Int` corresponding to the hole of type \mintinline{haskell}`Int` that still needs to be filled.
\end{itemize}

\mintinline{haskell}`fill` is probably the most interesting of the three, and will be the most used one too, because it enables the user to build data structures in a top-down approach, which complements very well the natural bottom-up way of constructing data structures in functional programming languages. Thanks to destinations, the user can now choose between those two approaches and pick the most efficient or more natural way for the problem at hand.

\mintinline{haskell}`fillComp` offers a way to mix both approaches: one can build small chunks in a top-down approach, and combine them together in a bottom-up fashion even if they aren't all complete.

\mintinline{haskell}`fillLeaf` is just a restriction of \mintinline{haskell}`fillComp`. It is used very frequently for types whose constructors aren't \mintinline{haskell}`Fill`able because they wrap over unpacked or primitive fields.

\TODO{Move the following paragraph elsewhere}

There is a duality between each constructor \mintinline[escapeinside=°°]{haskell}`C` with type \mintinline[escapeinside=°°]{haskell}`C :: (f°$_i$°)°$_{i \in 1..n}$° → a` and the associated destination-filling function \mintinline[escapeinside=°°]{haskell}`fill @'C :: Dest a ⊸ (Dest f°$_i$°)°$_{i \in 1..n}$°`: the side of the arrow on which types resides is flipped, and a \mintinline{haskell}`Dest` prefix is added to each of them. Destination-based data building can be seen as more general than the usual constructor based-approach, as one can alway emulate a given constructor \mintinline{haskell}`C` with destinations, as shown in table~\ref{table:emulate-ctor}, whereas all the advantages of DPS programming that we described in this section cannot be emulated by the use of constructors alone. 

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt,linenos,escapeinside=°°]{haskell}
C :: (f°$_i$°)°$_{i \in 1..n}$° → a

C' :: (f°$_i$°)°$_{i \in 1..n}$° → a
C' (x°$_i$°)°$_{i \in 1..n}$° = fromIncomplete_' (
  alloc <&> \(d :: Dest a) → case fill @'C d of
    (dx°$_i$°)°$_{i \in 1..n}$° -> ;;°$_{i \in 1..n}$° (fillLeaf x°$_i$° dx°$_i$°))
\end{minted}
\caption{Emulating a constructor \texttt{C} with the destination-filling function \texttt{fill @'C}}
\label{table:emulate-ctor}
\end{table}

\clearpage{}

\TODO{--------------- Arrêt relecture ---------------}

\section{Implementation}\label{sec:implementation}

\subsection{Compact Regions}\label{ssec:impl-compact-regions}

TODO: + précis; linker papier, expliquer que historiquement pour but sérialisation, préciser fonctionnement précis vis à vis du GC
TODO: rôle des compact regions ajd: GC savings pour données long-lived (exemple cache Arnaud) → Ici on pousse ce mécanisme plus loin

At the moment, destination-style programming is only possible in compact regions. Compact regions are special chunks on the heap that will only be very lightly inspected by the garbage collector, and thanks to that, we can do chirurgical memory updates in those without being afraid that it will interfere with garbage collection (especially move operations).

Because we have immobile chunks of memory, destinations can be implemented as a wrapper over a raw pointer which points to the memory location where data have to be written:

{\small
\begin{minted}{haskell}
data Dest r a = Dest Addr#
\end{minted}
}

The phantom type parameter \mintinline{haskell}`r` that is present everywhere in the API ensures that objects can only interact with other ones from the same region (as outgoing pointers across different regions are not allowed by design of Compact regions).

A \mintinline{haskell}`Region` object is implemented as a newtype over \mintinline{haskell}`Compact FirstInhabitant`, which is composed of a pointer to the region header, a lock (because compact region writes are not thread-safe at the primitive level), and a pointer to a \mintinline{haskell}`FirstInhabitant` inside the region.

\mintinline{haskell}`RegionToken r` carries a non-linear \mintinline{haskell}`Region` and is used when a \mintinline{haskell}`Proxy r` would be necessary anyway to infer the \mintinline{haskell}`r` of \mintinline{haskell}`Dest`/\mintinline{haskell}`Incomplete` in a function signature. \mintinline{haskell}`RegionContext r` makes the region argument implicit when the region identifier \mintinline{haskell}`r` is already part of the types of the function arguments.

\subsection{User-land haskell implementation details}
 
One issue I had during implementation was choosing the right representation for \mintinline{haskell}`a` in \mintinline{haskell}`Incomplete r a b`.

Ideally, we want \mintinline{haskell}`Incomplete r a b` to contains a \mintinline{haskell}`a` and a \mintinline{haskell}`b`, and let the \mintinline{haskell}`a` free when the \mintinline{haskell}`b` is fully consumed (or linearly transformed into \mintinline{haskell}`Ur c`). So the most straightforward representation of Incomplete would be a pair \mintinline{haskell}`data Incomplete r a b = Incomplete a b`.

It is also natural for \mintinline{haskell}`alloc` to return an \mintinline{haskell}`Incomplete r a (Dest a)`: as soon as the \mintinline{haskell}`Dest a` is linearly consumed, a \mintinline{haskell}`a` will be available.

However, building something of type \mintinline{haskell}`Incomplete r a (Dest a)` is not easy. The \mintinline{haskell}`Dest a` in question should carry the address of a memory cell in which the address of a constructor of type \mintinline{haskell}`a` will be written (by \mintinline{haskell}`fill` or a similar function). That memory cell is named \emph{root receiver}, because it will receive the address of the root of the object being built. Given the data definition above, the root receiver should hence be the first field of the \mintinline{haskell}`Incomplete` object. But the Incomplete object is not part of the compact region itself! It lives in the normal GC heap (which is crucial for early deallocation and memory optimizations); so it may move. As a result, we cannot just use the address of its left field as a destination and the left field as a root receiver.

The next natural move is to allocate a wrapper \mintinline{haskell}`W a` for \mintinline{haskell}`a` in the region, that will act as a root receiver, and have \mintinline{haskell}`data Incomplete r a b = Incomplete (W a) b`. Because the \mintinline{haskell}`a` will have to be wrapped in \mintinline{haskell}`Ur` when it is complete (see \mintinline{haskell}`fromRegion :: ∀ r a. (RegionContext r) ⇒ Incomplete r a () ⊸ Ur a`), we might as well use \mintinline{haskell}`Ur` as a wrapper and declare \mintinline{haskell}`data Incomplete r a b = Incomplete (Ur a) b`. It solves the previous issue of not having a receiver to write into.

Unfortunately, that approach is quite unsatisfying because any \mintinline{haskell}`Incomplete` object will now allocate a few words into the region that won't be collected for a long time. In particular, putting a non-linear value inside the region with \mintinline{haskell}`intoRegion :: ∀ r a. RegionToken r ⊸ a → Incomplete r a ()` will allocate an unnecessary \mintinline{haskell}`Ur` wrapper, as the object is already fully built, and thus doesn't need a root receiver. With the \mintinline{haskell}`Ur` solution, it's no longer efficient to write \mintinline{haskell}`fillLeaf` as a composition \mintinline{haskell}`fillComp . intoRegion (getToken @r)`, and \mintinline{haskell}`fillLeaf` needs a dedicated optimized implementation.

Another approach we explored is to represent an \mintinline{haskell}`Incomplete` as a piece of data structure that would be concretized when it is given a root receiver. Delaying the construction of the structure that way is not efficient though, because instead of writing a structure to memory, we create huge closures representing the action of creating the structure.

Finally, I decided to embed the \mintinline{haskell}`a` field in \mintinline{haskell}`Incomplete` not in a regular data constructor wrapper, but instead in a STG indirection closure (\mintinline{haskell}`stg_IND` symbol). The indirection closure is allocated into the compact region in the \mintinline{haskell}`alloc` case (for the same reasons as the \mintinline{haskell}`Ur` above was), but no indirection closure is needed in \mintinline{haskell}`intoRegion`, we can just store the fully built \mintinline{haskell}`a` directly in \mintinline{haskell}`Incomplete`. That way, we keep uniformity in the typing and runtime behaviour of \mintinline{haskell}`Incomplete` in both cases (as indirections are transparent for the RTS), and ensure that the overhead of `fillLeaf`/\mintinline{haskell}`intoRegion` is very small, at the cost of a few more alloc-ed words for each call of \mintinline{haskell}`alloc`. This is a fair price to pay because any real-world program should call \mintinline{haskell}`fillLeaf` way more than \mintinline{haskell}`alloc` (which is only required to create the root of a new big object).

The implementation of \mintinline{haskell}`fromRegion` and \mintinline{haskell}`fromRegionExtract` is then relatively straightforward. \mintinline{haskell}`fromRegion :: ∀ r a. (RegionContext r) ⇒ Incomplete r a () ⊸ Ur a` discards the \mintinline{haskell}`()` value carried by the Incomplete, allocates a \mintinline{haskell}`Ur _` in the region, writes the address of the \mintinline{haskell}`a` value into the \mintinline{haskell}`Ur` slot, and returns it. \mintinline{haskell}`fromRegionExtract :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a (Ur b) ⊸ Ur (a, b)` allocates a \mintinline{haskell}`Ur (_, _)` into the region, checks whether the \mintinline{haskell}`b` in \mintinline{haskell}`Ur b` is already part of the region or not (and copies it into the region if it isn't), and writes the address of the \mintinline{haskell}`a` and \mintinline{haskell}`b` values into the slots of the \mintinline{haskell}`Ur`ed pair before returning it.

\paragraph{Deriving \mintinline{haskell}`Fill` for all datatypes with `Generics`}

The \mintinline{haskell}`Fill lCtor r a` class has only one method, \mintinline{haskell}`fill :: Dest r a → DestsOf lCtor r a`.

As it has been said before, the action of \mintinline{haskell}`fill @lCtor @r @a` is to allocate a new hollow constructor \mintinline{haskell}`Ctor _ :: a` in the region, and fill a destination of type \mintinline{haskell}`Dest r a` with its address. Because the constructor is hollow (i.e. its fields haven't been initialized), \mintinline{haskell}`fill` should also return destination objects pointing to these incomplete fields a.k.a. holes.

The type of the destinations that should be returned by \mintinline{haskell}`fill` can be computed by carefully inspecting the \mintinline{haskell}`Generic` representation of the type \mintinline{haskell}`a`. Indeed, GHC.Generics is a haskell library that provides compile-time inspection of a type metadata (list of constructors, fields, memory representation...) if the type implements the \mintinline{haskell}`Generic` class. Fortunately, the implementation of the \mintinline{haskell}`Generic` class be derived automatically by the compiler (instead of being implemented manually), making it easy to use for user-defined types.

In the \mintinline{haskell}`DestsOf` type family and in in the different \mintinline{haskell}`Fill` instance heads, I inspect the \mintinline{haskell}`Generic` representation of the given type \mintinline{haskell}`a` to find the metadata of the constructor whose lifted representation is \mintinline{haskell}`lCtor`, and then I extract the number of fields of the constructor and their types.

For example, the \mintinline{haskell}`Generic representation` of \mintinline{haskell}`Maybe a` gives

{\small
\begin{minted}[escapeinside=°°]{haskell}
M1 D (MetaData "Maybe" "GHC.Maybe" "base" False) (
  M1 C (MetaCons "Nothing" PrefixI False) U1
  :+: M1 C (MetaCons "Just" PrefixI False) (M1 S [...] (K1 R a)))
\end{minted}
}

indicating that there is zero fields with constructor \mintinline{haskell}`Nothing` and one field of type \mintinline{haskell}`a` with constructor \mintinline{haskell}`Just`. 


The representation for \mintinline{haskell}`(a, b)` gives

{\small
\begin{minted}[escapeinside=°°]{haskell}
  M1 D (MetaData "Tuple2" "GHC.Tuple.Prim" "ghc-prim" False) (
    (M1 C (MetaCons "(,)" PrefixI False) (
      M1 S [...] (K1 R a)
      :*: M1 S (K1 R b))))
\end{minted}
}

indicating that there are two fields, one of type \mintinline{haskell}`a` and one of type \mintinline{haskell}`b`, with the \mintinline{haskell}`(,)` data constructor.

Fields of a constructor are stored contiguously in memory, at offset $i \times \textit{wordsize}_{(i \in 1..n)}$ from the constructor base address. So \mintinline{haskell}`fill` just harvests the field metadata and can easily build as many destinations as there are fields, using the address of the newly allocated constructor as a base point. The extracted types of the fields are used to specify the phantom type parameter of the destinations.

\subsection{Changes to GHC's internals and RTS}

The implementation we described in the previous parts relies on being able to allocate hollow constructors. This is the key point of destination-style programming: building structures in a top-down approach, where nodes deeper in the data tree are left unspecified for some time.

Usually, in Haskell, every field must be explicitly specified to allocate a constructor closure. This definitely makes sense as there is no (safe) way to later update a field in a mutable/in-place fashion; so an unspecified field would stay unspecified forever.

Of course, it is possible to overcome that well-founded rule by using a unique \emph{joker value} for every field of a constructor: \mintinline{haskell}`Right undefined` or \mintinline{haskell}`(undefined, undefined)` are valid haskell values that shouldn't blow up too fast. Using an unsafe coercion works too: \mintinline{haskell}`(unsafeCoerce (), unsafeCoerce ()) :: (a, b)` is valid. Theoretically, we hence have a way to allocate a somewhat hollow constructor.

That being said, there is no primitive in GHC at the moment that allows to allocate a value directly in a compact region. The only way to put something in a region is to copy something that has already been allocated in the normal GC heap. So even with the trick described above, the constructor closure would need to be allocated twice.

As a result, in order to obtain the maximum performance and memory gains from the use of destination, I had no other choice than to tweak the GHC compiler and add a new primitive operation (\emph{primop}) in charge of allocating a hollow constructor directly into a compact region.

\paragraph{About GHC architecture, RTS and primops}

GHC is the main compiler for the Haskell programming language, and its compilation model involves several intermediary languages.

First, Haskell code is turned into Core, a typed language whose syntax is mostly a subset of Haskell one. A lot of Haskell constructs are desugared into constructors and case expressions, type applications are made explicit, etc.
Then, several optimization steps are made on the Core output, like removing case expressions on known constructors, or floating \mintinline{haskell}`let` expressions (moving them upwards in the code to factor out some computations).

When all Core optimizations have been made, Core code is then transformed into STG code. In STG, all memory objects (called \emph{closures}) have the same memory representation, in the form of a pointer to a struct called the \emph{info table}, and a payload of a variable size (composed of primitive values and pointers to other closures). Because Haskell works in a lazy fashion, closures might not represent evaluated values, so the info table of each closure contains a pointer to a block of code that is responsible for evaluating the sub-expression that the closure represents. In other terms, the caller is not responsible for knowing how to evaluate the closure, but the closure itself is.
As you can imagine, having a dedicated info table with each closure would be excessively expensive memory-wise (as both of them would need to be dynamically allocated). Instead, the STG uses sharing as most as possible, and for example, every dynamic closure representing the constructor application of a given constructor (let's say \mintinline{haskell}`Just`) will have the same info table pointer, pointing to a single statically-allocated info table. Indeed, no matter what type of argument it is applied to, every \mintinline{haskell}`Just` instance will have the same memory layout (only one boxed argument as a payload), and the same evaluation code (doing nothing and returning immediately because a constructor application is already in weak-head normal form). That kind of sharing in fact quite common in other programming languages too: virtual tables are shared in the same way in C++.

Other specific info tables are also being shared in the STG: the ones for "blackholes" (which is used to indicate that a closure is currently under evaluation by a thread and that its result is still pending); the ones for indirection, etc.

All that sharing is made through the use of labels:

\begin{itemize}

\item when the declaration of a data constructor is encountered (definition site), the corresponding info table is emitted to the static area of the output program, and its address is associated with the label \mintinline{haskell}`<constructor name>_con_info`
\item when the use of a data constructor is encountered, the label \mintinline{haskell}`<constructor name>_con_info` is used in place of an actual address in the closure that is emitted
\item later on in the compilation process, those labels will be converted by the linker into actual addresses

\end{itemize}

Now, the runtime behaviour of a Haskell program is directed by the \emph{run-time system}, or RTS, which is a software component written in a mix of C and C-- (the last language in the compilation pipeline of Haskell for a native build). The RTS is built once for all when GHC itself is being built, and it is then included in every executable produced by GHC.

Its role is to manage threads, organize garbage collection and also to manage compact regions (among other things). The RTS defines various primops that allow the haskell programmer to interact with it for those needs. For example, \mintinline{haskell}`compactAdd#` is the primitive operation that copies a closure into an existing compact region, fully evaluating its potentiel sub-expressions along the way.

There are also primops in GHC which are meant to be resolved at the \emph{Core to Stg} phase (emitting some code at compile time), but which don't trigger any specific interaction with the RTS at runtime. Among those are all the primitive numeric operators on primitive types (\mintinline{haskell}`+#`, \mintinline{haskell}`-#`...), and more generally all the performance-critical operations working on unboxed types, and which don't require any specific interaction or precaution with garbage collection or thread execution, or don't need a specific allocation scheme, etc.

It is important to note for the next of that part that the RTS cannot really access information that would have been made available during the compilation of a specific haskell program. Indeed, the RTS included in the final executable for the given program is the same as the one included in all other executables made with the same version of GHC; it isn't possible to parametrize the RTS with data collected during the compilation of the given program (ex: types used or defined in the program). The only data channel I found between the compilation stage of a program and the RTS is to reify the needed compile-time information into a runtime value that will later be passed to the RTS through a primop call.

\paragraph{New primops to support destination-style programming}

What I want to do is twofold:
\begin{itemize}
\item First, add a primop to the RTS to allocate space into a compact region for a hollow constructor;
\item Second, add a non-RTS primop to reify the necessary information about a constructor into a runtime-value so that it can be communicated to the RTS (because the RTS cannot access that itself, as I explained above)
\end{itemize}

The first step mostly takes place in \mintinline{text}`rts/Compact.cmm`, the main C-- module of the RTS for compact regions management, as presented in table~\ref{table:impl-compactAddHollow}.

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt]{c}
// compactAddHollow# :: Compact# → Addr# → State# RealWorld → (# State# RealWorld, a #)
stg_compactAddHollowzh(P_ compact, W_ info)
{
    W_ pp, ptrs, nptrs, size, tag, hp;
    P_ to, p;
    again: MAYBE_GC(again);
    STK_CHK_GEN();

    pp = compact + SIZEOF_StgHeader + OFFSET_StgCompactNFData_result;
    ptrs  = TO_W_(%INFO_PTRS(%STD_INFO(info)));
    nptrs  = TO_W_(%INFO_NPTRS(%STD_INFO(info)));
    size = BYTES_TO_WDS(SIZEOF_StgHeader) + ptrs + nptrs;
    p = NULL;  // p isn't actually used by ALLOCATE macro

    ALLOCATE(compact, size, p, to, tag);
    P_[pp] = to;
    SET_HDR(to, info, CCS_SYSTEM);
#if defined(DEBUG)
    ccall verifyCompact(compact);
#endif
    return (P_[pp]);
}
\end{minted}
\caption{Implementation of \texttt{compactAddHollow\#} in the RTS}
\label{table:impl-compactAddHollow}
\end{table}

The \mintinline{c}`stg_compactAddHollowzh` function is mostly a glorified call to the \mintinline{haskell}`ALLOCATE` macro defined in the same file, which tries to do a pointer-bumping alloc in the current block of the compact region if there is enough space, and otherwise add a new block to the region.

As we said earlier, \mintinline{haskell}`stg_compactAddHollowzh`/\mintinline{haskell}`compactAddHollow#` needs to access the info table pointer of the constructor we want to allocate, but cannot do so directly as the RTS cannot access STG labels. This is why the function must receive a \mintinline{haskell}`info` parameter of type \mintinline{haskell}`W_`/\mintinline{haskell}`Addr#` (the former is the C-- type; the latter is the Haskell one).

Let's see how to reify the info table pointer of a constructor into a runtime value now. We want to add a new primitive operation in GHC that takes a compile-time-known string or constructor as input and compiles down to the label having that name or corresponding to the constructor's info table pointer.

In Haskell, compile-time-known strings are represented by a type-level string literal of kind \mintinline{haskell}`Symbol`, and constructors can be lifted into type literals as well (with \mintinline{haskell}`LANGUAGE DataKinds` and prefixing the constructor with \mintinline{haskell}`'`, e.g. \mintinline{haskell}`'Just`). So the function we would like to build must have a type parameter somewhere, probably in one of its argument types, corresponding to that type-level literal input, like \mintinline{haskell}`reifyStgInfoPtr# :: Proxy# s → Addr#` (where \mintinline{haskell}`s` would stand for the lifted constructor or symbol).

The problem is, the compilation pipeline only start emitting labels at the \emph{STG to C--} phase. And at that point, almost all type information for polymorphic primops' parameters have been erased. Fortunately, for some technical reason, information about the actual return type of a primop is retained that late in the compilation process.

Here's the trick I used so: I built a dedicated return type for \mintinline{haskell}`reifyStgInfoPtr#`, namely \mintinline{haskell}`InfoPtrPlaceholder# a`. That type has a phantom type parameter but shares the same memory representation as \mintinline{haskell}`Addr#`. That way, it is possible to use a type hint to provide the type-level literal to the primop: \mintinline{haskell}`reifyStgInfoPtr# (# #) :: InfoPtrPlaceholder# a` will allow the implementation of \mintinline{haskell}`reifyStgInfoPtr#` to read the type parameter \mintinline{haskell}`a` even though it is both phantom and in return position.

The gist of this implementation is presented in table~\ref{table:impl-reifyStgInfoPtr}, which we will now comment a bit.

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
case primop of
  [...]
  ReifyStgInfoPtrOp → \_ →  -- we don't care about the function argument (# #)
    opIntoRegsTy $ \[res] resTy → emitAssign (CmmLocal res) $ case resTy of
      -- matches when 'a' is a Symbol, and extracts the symbol value as a FastString in 'sym'
      TyConApp _addrLikeTyCon [_typeParamKind, LitTy (StrTyLit sym)] →
        CmmLit (CmmLabel (mkCmmInfoLabel rtsUnitId (fsLit "stg_" `appendFS` sym)))
      -- matches when 'a' is a lifted data constructor, and extracts it as a DataCon (from GHC.Core.DataCon)
      TyConApp _addrLikeTyCon [_typeParamKind, TyConApp tyCon _] | Just dataCon <- isPromotedDataCon_maybe tyCon → do
        CmmLit (CmmLabel (mkConInfoTableLabel (dataConName dataCon) DefinitionSite))
      -- return garbage data when no pattern matches
      _ → [...]
  [...]
\end{minted}
\caption{Implementation of \texttt{reifyStgInfoPtr\#} in GHC}
\label{table:impl-reifyStgInfoPtr}
\end{table}

Going from the \mintinline{haskell}`InfoPtrPlaceholder# a` returned by \mintinline{haskell}`reifyStgInfoPtr#` to an actual \mintinline{haskell}`Addr#` is just a matter of calling the \mintinline{haskell}`unsafeCoerceAddr` function supplied by GHC, as both type are represented by pointers/addresses under the hood.

With both primops in hand, we can allocate a hollow constructor closure directly in a compact region in an efficient fashion. For example, for \mintinline{haskell}`Just`, one should do:
{\small
\begin{minted}{haskell}
hollowJust :: Maybe a
hollowJust = compactAddHollow#
  compactRegion#
  (unsafeCoerceAddr (reifyStgInfoPtr# (# #) :: InfoPtrPlaceholder# 'Just))  
\end{minted}
}

It would probably be possible to merge the two primops into a two-stage one (with both a compile-time and run-time action) without too much effort.

\paragraph{Destination-style programming with stock GHC}

During the early days of my research, I first experimented with hollow allocation without any modification to GHC codebase. Instead of using the primops I described above, I made heavy use of runtime heap inspection and \mintinline{haskell}`GHC.Generics` trickery to build hollow constructors with the correct info table pointers. As a result, it is still possible to use destinations-style programming without using a patched version of GHC, but performance gains are not guaranteed in that context.

TODO: si temps restant, comparer les performances

\section{Evaluating performance of destination-style programming}

\subsection{Benchmarking / profiling strategy}

Benchmarking code using destination hasn't been easy.

First, the current implementation of destinations for Haskell uses compact regions, which force strictness "for free", whereas regular Haskell code is lazy by default; and thus the produced data structures need to be explicitly forced into normal form.

There are two main ways to force a structure into normal form. The first one is to use the tools supplied by the \mintinline{haskell}`deepseq` package. That packages defines a typeclass, \mintinline{haskell}`NFData`, which can be easily derived for user-defined datatypes, which in turn gives access to functions like `force' or `rnf' that will force every thunk (pending lazy computation) from a value/structure. Using \mintinline{haskell}`deepseq` to benchmark the naive implementation (the one without destinations) has the advantage of not making unnecessary allocations, so the reported memory usage is accurate, but the \emph{forcing} operation might incur extra CPU usage and thus slow the program down, because forcing thunk artificially with \mintinline{haskell}`force` or \mintinline{haskell}`rnf` is not as efficient as if they were forced in an organic way by the RTS during the program execution.

The second way to force a lazy structure into normal form is to copy it into a compact region. Indeed, the \mintinline{haskell}`compact`/\mintinline{haskell}`compactAdd` functions from \mintinline{haskell}`GHC.Compact` will efficiently force every thunk of a structure before writing their final value into the region. Most of the time, using \mintinline{haskell}`compact` is faster than using \mintinline{haskell}`force`, as the  \emph{forcing} code is written in C/C-- instead of Haskell, but it creates two issues:

\begin{itemize}
  \item the space allocated in the region for the result is counted towards the total memory allocated by the program. However, compact regions aren't suited for all use-cases. For some of them, the GC gains they would offer wouldn't balance for the extra time during which some garbage will continue to live in memory. As a result, it seems unfair to count the extra memory usage in the region incurred by \mintinline{haskell}`compact` for programs which wouldn't make use of compact regions in normal time (as the result structure is already present in the normal GC heap);
  \item \mintinline{haskell}`compact` not only forces all thunks, but also copies their final value into the region. The time required to make the copy, despite being small, is still counted towards the total execution time of the program.
\end{itemize}

To my knowledge, there is no better way than these two to mesure the time taken by a strict program and by a lazy program, in an accurate and fair way.


\begin{itemize}
\item Three modes (-T, -s, -p)
\item How to evaluate naive code (why we use both copyIntoRegion and force)
\end{itemize}

\subsection{Performance of map implementation (in a strict context)}

\begin{itemize}
\item How this is important for Ocaml
\end{itemize}

\subsection{Performance of the SExpr parser}

\subsection{Performance of BFS Tree traversal}\label{ssec:benchmark-parser}

\subsection{Qualitative evaluation of destination code VS naive code}

\begin{itemize}
\item TODO: implement a naive implement of functional mapMBFS
\item \end{itemize}

\section{Conclusion and related work}
\begin{itemize}
\item Why it's an improvement over Minamide

\item Lifting the non-linear restriction for elements stored in dest-allocated structures (= requires more theoretical work)

\item Using destinations in different contexts than compact regions (normal GC heap, other kinds of chunk-allocated memory)
\end{itemize}

\appendix

\section{Full implementation of the S-expression parser}\label{ann:parse-s-expr}

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
parseSExpr :: ByteString → Int → Either Error SExpr
parseSExpr bs i = case bs !? i of
  Nothing → Left (UnexpectedEOFSExpr i)
  Just c → case c of
    ')' → Left (UnexpectedClosingParen i)
    '(' → parseSList bs (i + 1) []
    '"' → parseSString bs (i + 1) False []
    _ →
      let tok = extractNextToken bs i -- take chars until delimiter/space
        in if null tok
            then -- c is a (leading) space, skip it and recurse
              parseSExpr bs (i + 1)
            else case parseInt tok of
              Just int → Right (SInteger (i + length tok - 1) int)
              Nothing → Right (SSymbol (i + length tok - 1) (toString tok))

parseSList :: ByteString → Int → [SExpr] → Either Error SExpr
parseSList bs i acc = case bs !? i of
  Nothing → Left (UnexpectedEOFSList i)
  Just c → if
    | c == ')' → Right (SList i (reverse acc))
    | isSpace c → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        Left err → Left err
        Right child → parseSList bs (endPos child + 1) (child : acc)

parseSString :: ByteString → Int → Bool → [Char] → Either Error SExpr
parseSString bs i escape acc = case bs !? i of
  Nothing → Left (UnexpectedEOFSString i)
  Just c → case c of
    '"'  | not escape → Right (SString i (reverse acc))
    '\\' | not escape → parseSString bs (i + 1) True acc
    'n'  | escape → parseSString bs (i + 1) False ('\n' : acc)
    _ → parseSString bs (i + 1) False (c : acc)
\end{minted}
\caption{Implementation of the S-expression parser without destinations}
\label{table:impl-sexpr-parser-without-dest}
\end{table}

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt,linenos,escapeinside=°°]{haskell}
parseSExprDPS :: ByteString → Int → Dest SExpr ⊸ Either Error Int
parseSExprDPS bs i d = case bs !? i of
  Nothing → °\mnew{fillLeaf defaultSExpr d}° ;; Left (UnexpectedEOFSExpr i)
  Just c → case c of
    ')' → °\mnew{fillLeaf defaultSExpr d}° ;; Left (UnexpectedClosingParen i)
    '(' → parseSListDPS bs (i + 1) °\mnew{(fill @'SList d)}°
    '"' → parseSStringDPS bs (i + 1) False °\mnew{(fill @'SString d)}°
    _ →
      let tok = extractNextToken bs i -- take chars until delimiter/space
        in if null tok
            then -- c is a (leading) space, skip it and recurse
              parseSExprDPS bs (i + 1) d
            else case parseInt tok of
              Just int →
                let °\mnew{!dint = fill @'SInteger d}° in
                  °\mnew{fillLeaf int dint}° ;; Right (i + length tok - 1)
              _ →
                let °\mnew{!dsym = fill @'SSymbol d}° in
                  °\mnew{fillLeaf (toString tok) dsym}° ;; Right (i + length tok - 1)

parseSListDPS :: ByteString → Int → Dest [SExpr] ⊸ Either Error Int
parseSListDPS bs i d = case bs !? i of
  Nothing → °\mnew{fill @'[] d}° ;; Left (UnexpectedEOFSList i)
  Just c → if
    | c == ')' → °\mnew{fill @'[] d}° ;; Right i
    | isSpace c → parseSListDPS bs (i + 1) d
    | otherwise →
        let !(dh, dt) = °\mnew{fill @'(:) d}°
        in case parseSExprDPS bs i °\mnew{dh}° of
              Left err → fill @'[] dt ;; Left err
              Right endPos → parseSListDPS bs (endPos + 1) °\mnew{dt}°

parseSStringDPS :: ByteString → Int → Bool → Dest [Char] ⊸ Either Error Int
parseSStringDPS bs i escape d = case bs !? i of
  Nothing → °\mnew{fill @'[] d}° ;; Left (UnexpectedEOFSString i)
  Just c → case c of
    '"'  | not escape → °\mnew{fill @'[] d}° ;; Right i
    '\\' | not escape → parseSStringDPS bs (i + 1) True d
    'n'  | escape →
        let °\mnew{!(dh, dt) = fill @'(:) d}°
          in °\mnew{fillLeaf '\textbackslash{}n' dh}° ;; parseSStringDPS bs (i + 1) False °\mnew{dt}°
    _ →
        let °\mnew{!(dh, dt) = fill @'(:) d}°
          in °\mnew{fillLeaf c dh}° ;; parseSStringDPS bs (i + 1) False °\mnew{dt}°
\end{minted}
\caption{Implementation of the S-expression parser with destinations}
\label{table:impl-sexpr-parser-with-dest}
\end{table}
\clearpage{}
\printbibliography

\end{document}
