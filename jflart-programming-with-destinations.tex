\documentclass[english]{jflart}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{minted}
\usepackage{etoolbox,xpatch}
\usepackage{ tipa }
\usepackage{float}
\usepackage[normalem]{ulem}
\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{bibliography.bib}

% Numéro et année des JFLAs visées par l'article, obligatoire.
\jfla{35}{2024}

\title{Destination-passing style programming: a Haskell implementation}
% Un titre plus court, optionnel.
%\titlerunning{Du bon usage de~\texttt{jflart.cls}}

% Auteurs, liste non abrégée.
\author[1]{Thomas Bagrel}
% \author[2]{Cunégonde Martin}
% \author[2]{Odoacre Contempierre}
% Une liste d'auteurs abrégée à utiliser à l'intérieur de l'article.
\authorrunning{Bagrel}

% Affiliations des auteurs
\affil[1]{INRIA/LORIA, Vand\oe{}uvre-lès-Nancy, 54500, France}
\affil[2]{TWEAG, Paris, 75012, France}

% Une commande définie par l'utilisateur
\newcommand{\cmd}[1]{\texttt{\textbackslash {#1}}}
\newcommand{\mpar}{\text{\,\textramshorns\,}}
\newcommand{\dest}{-\prec}
\newcommand{\TODO}[1]{{\color{red}\large #1}}
\usepackage{newunicodechar}
\newunicodechar{⊸}{\ensuremath{\multimap}}
\newunicodechar{→}{\ensuremath{\to}}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{;}{\textbf{\large ;}}
\newunicodechar{∀}{\ensuremath{\forall}}
\makeatletter
\AtBeginEnvironment{minted}{\dontdofcolorbox}
\def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
\xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
\xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{} % see https://tex.stackexchange.com/a/401250/
\makeatother

\begin{document}

\maketitle

\begin{abstract}
Destination-passing style programming introduces destinations, which represents the address of a write-once memory cell. Those destinations can be passed around as function parameters, and thus enable the caller of a function to keep control over memory allocation: the body of the called function will just be responsible of filling that memory cell. This is especially useful in functional programming languages such as Haskell, in which the body of a function is typically responsible for allocation of the result value.

Programming with destination in Haskell is an interesting way to improve performance of critical parts of some programs, without sacrificing memory warranties. Indeed, thanks to a linearly-typed API we designed, a write-once memory cell cannot be left uninitialized before being read, and is still disposed of by the garbage collector when it is not in use anymore, eliminating the risk of uninitialized read, memory leak, or double-free errors that can arise when memory is handled manually.

With the implementation of destinations for Haskell through compact regions we provide in this article, we reach a 15-40\% improvement over memory allocation in a simple parser example, and 0-50\% improvement in run time. We also provide a few examples of programs that can be implemented in a tail-recursive fashion thanks to destinations, which is crucial for performance in strict contexts.

Safety proofs for the API are not provided in this article though, and will be the subject of a future article.
\end{abstract}

\tableofcontents{}

\section{Introduction}

TODO: conceptuellement simple, mais beaucoup d'obstacles techniques pour rendre ça possible.

 Destinations bring a taste of imperative programming in a pure functional environnement when performance really matters, without breaking memory safety.

Using destinations as a way of allocating and building functional data structures can lead to better time and/or space performance for critical parts of a program, but destinations also increase expressiveness of a functional language.

\subsection{Problem space and motivation}

\subsection{Framework}

\begin{itemize}

\item GHC where purity is enforced
\item Also because it has good support for linear type discipline
\item Linear types
\item Destinations
\item Compact regions
\item strict lazy haskell

\end{itemize}

(préliminaire car ça existe déjà)

Article à destination des experts haskell ? CamL?

\section{Motivating examples for destination-passing style programming}

Destination-passing style programming, which will be abbreviated DPS programming in the rest of the article, takes its source in the early days of imperative languages with manual memory management. In the C programming language, it's quite common for a function not to allocate memory itself for its result, but rather to receive a reference to a memory location where to write its result (often named \emph{out(put) parameter}). In that scheme, the caller of the function is both responsible for allocation and disposal of the cell in which the value will live. This is exactly what DPS programming is about: take control from the callee back to the caller about memory management.

DPS programming need a concept of reference or pointer to communicate the location of the memory cell in which the called function should write its result. In functional programming languages, these are often named \emph{destinations}, so we will use this name to refer to the address of a write-once memory cell in Haskell.

It's time to see why DPS programming can be useful even in a pure functional context such as Haskell.

\subsection{Efficient \emph{Difference list} implementation}

Linked lists are a staple of functional programming, but they aren't efficient for concatenation, especially when the concatenation calls are nested to the left.

In an imperative context, it would be quite easy to concatenate linked lists efficiently. One just have to keep both a pointer to the root and to the last \emph{cons} cell of each list. Then, to concatenate two lists, one just have to mutate the last \emph{cons} cell of the first one to point to the root of the second list.

This isn't possible to do in an immutable functional context though. Instead, \emph{Difference lists} can be used: they are structures that are fast to convert into lists ($\mathcal{O}(1)$ amortized) and tend to emulate the idea of having a mutable (here, write-once) last \emph{cons} cell. Usually, a difference list \mintinline{haskell}`[x1, ..., xn, ?]` is encoded by a function taking a last element \mintinline{haskell}`ys` of type \mintinline{haskell}`[a]` and returning \mintinline{haskell}`x1 : ... : xn : ys` (having type \mintinline{haskell}`[a]` too). \TODO{reference for difference list paper}

With such representation, concatenation is just function composition: \mintinline{haskell}`f1 <> f2 = f1 . f2`, and we have \mintinline{haskell}`mempty = id`\footnote{\mintinline{haskell}`mempty` and \mintinline{haskell}`<>` are the standard notations for the neutral element and internal operation of a monoid in Haskell}, \mintinline{haskell}`toList f = f []` and \mintinline{haskell}`fromList xs = \ys → xs ++ xs`.

In DPS, instead of encoding the concept of a write-once hole with a function, we can represent it as a first-class object with a \emph{destination}. A difference list now become a first class data structure in memory, albeit incomplete, with two handles: one to the root of the list of type \mintinline{haskell}`[a]`, and one to the yet-to-be-filled hole in the last cons cell, represented by a destination of type \mintinline{haskell}`Dest [a]`.

With the function encoding, it isn't possible to read the list until a last element of type \mintinline{haskell}`[a]` have been supplied to complete it. With the destination representation, this constraint persists: the actual list \mintinline{haskell}`[a]` isn't readable until the accompanying destination is filled (or \emph{linearly consumed}, as we sometimes write). This constraint is embodied by the \mintinline{haskell}`Incomplete a b` type of our destination API: \mintinline{haskell}`b` is what needs to be linearly consumed to make the \mintinline{haskell}`a` readable. A difference list is then \mintinline{haskell}`type DList a = Incomplete [a] (Dest [a])`: one should fill the \mintinline{haskell}`Dest [a]` (with a \mintinline{haskell}`[a]`) to get a readable \mintinline{haskell}`[a]`.

The implementation of operations on destination-backed difference lists are presented in table~\ref{table:impl-dlist}.
\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
data [a] -- built-in
  = []        -- nil constructor
  | (:) a [a] -- cons constructor

type DList a = Incomplete [a] (Dest [a])

alloc :: DList a

append :: DList a ⊸ a → DList a
append i x =
  i <&> \dl → case fill @'(:) dl of
    (dh, dt) → fillLeaf x dh ;; dt

concat :: DList a ⊸ DList a ⊸ DList a
concat i1 i2 = i1 <&> fillComp i2

toList :: DList a ⊸ [a]
toList i = fromIncomplete_' (i <&> \dl → fill @'[] dl)
\end{minted}
\caption{Implementation of difference lists with destinations}
\label{table:impl-dlist}
\end{table}

\begin{itemize}
  \item \mintinline{haskell}`alloc` returns a \mintinline{haskell}`DList a` which is exactly an \mintinline{haskell}`Incomplete [a] (Dest [a])` structure. There is no data there yet; so the list that will be fed in the \mintinline{haskell}`Dest [a]` is exactly the list in that the \mintinline{haskell}`Incomplete` will hold. This is highly similar to the \mintinline{haskell}`id` function which represents the empty destination list in the function encoding.
  \item \mintinline{haskell}`append` fills the the hole at the end of the list \mintinline{haskell}`dl` with a new \emph{cons} cell, using \mintinline{haskell}`fill @'(:)`. The head of that cell \mintinline{haskell}`dh` is filled with the value to append using \mintinline{haskell}`fillLeaf`, and the remaining hole of the new \emph{cons} cell, represented by \mintinline{haskell}`dt :: Dest [a]`, is the hole of the resulting difference list.
  \item \mintinline{haskell}`concat` calls \mintinline{haskell}`fillComp`, which fills the destination of the first difference list \mintinline{haskell}`i1` with the root of the second list. The resulting \mintinline{haskell}`Incomplete` object hence has the same root as the first list, holds the elements of both lists, and has the hole of the second list at the end. Memory-wise, \mintinline{haskell}`concat` will just write the address of the root of the second list into the hole of the first one ; no move is required.
  \item \mintinline{haskell}`toList` completes the incomplete structure by plugging \emph{nil} into its hole with \mintinline{haskell}`fill @'[]`.
\end{itemize}

This simplified API for difference lists still lacks some linearity requirements to make it write-once/immutable. In particular, the result of \mintinline{haskell}`alloc` should be used linearly but this isn't enforced by this API, and as a result, one could fill the embedded destination twice. Linearity concerns will be addressed in section~\ref{sec:api} .

That being said, thanks to destination-style programming, not only we can express programs and functions whose implementation is closer to their intended memory behaviour (here, implementing data structures with holes), but we can also get important performance improvements as a side benefit. \TODO{one sentence about the benchmark results compared to the function encoding}

\subsection{Breadth-first tree traversal}

The idea of functional data structure with write-once holes is not new. In 1998, Minamide already proposed in~\cite{minamide_functional_1998} a variant of lambda calculus with support for \emph{hole abstractions}, which can be represented in memory by an incomplete structure with one hole and can be composed efficiently with each other (as with \mintinline{haskell}`fillComp` above). With such framework, it is fully possible to implement destination-backed difference lists, as we developed in the previous section.

However, in Minamide's work, there is no concept of destination: the hole in a structure can only be filled if one has the structure itself at hand. On the other hand, our paper introduces destinations, which are a way to interact with a hole remotely, even when one doesn't have a handle to the associated data structure. Because destination are treated as first-class objects, they can be passed around or stored in collections or other structure. Being able not only to represent data structures with holes, but also manipulate references to these holes as first-class objects while preserving memory safety, is the major step forward that this paper presents.

The fact that destinations can be stored in arbitrary data structures opens the way for more natural and efficient implementations of some functional data structure algorithms, for example breadth-first tree traversal, which isn't easy to implement in a standard immutable setting.

In breadth-first tree traversal (with effects), the order in which effects should be sequenced is completely different than the natural order of traversal of the tree. As a result, many tricks should be employed to reconciliate those two realities. Even the most elegant solutions such as \cite{gibbons_phases_2023} often involve several traversals of the tree, or the construction of additional cost-heavy structures.

With storable destinations in our toolbelt, we can implement a solution that is both easy to write and efficient, doing only a single traversal pass on the original tree. The main idea is to keep a queue of pairs, whose first component is the next node from the input tree to process, and the second is a destination referring to the location in the output tree where to write the result of processing that node. Thanks to destination, it is possible to let some parts of the tree "unfinished" for some time, and to come back at them later when it's their turn to be processed. And storing destinations in a queue allows the effects to be applied in a breadth-first order so that the tree can be built in one pass. The implementation is provided in table~\ref{table:impl-bfs-tree-traversal}.

\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
data Tree a = Nil | Node a (Tree a) (Tree a)

mapAccumBFS :: ∀ a b s. (s → a → (s, b)) → s → Tree a → (Tree b, s)
mapAccumBFS f s0 tree =
  fromIncomplete' (
    alloc <&> \dtree → go s0 (singleton (Ur tree, dtree)))
  where
    go :: s → Queue (Ur (Tree a), Dest (Tree b)) ⊸ Ur s
    go s q = case dequeue q of
      Nothing → Ur s
      Just ((utree, dtree), q') → case utree of
        Ur Nil → fill @'Nil dtree ;; go s q'
        Ur (Node x tl tr) → case fill @'Node dtree of
          (dr, dtl, dtr) →
            let q'' = q' `enqueue` (Ur tl, dtl) `enqueue` (Ur tr, dtr)
                (s', r) = f s x
              in fillLeaf r dr ;; go s' q''
\end{minted}
\caption{Implementation of breadth-first tree traversal with destinations}
\label{table:impl-bfs-tree-traversal}
\end{table}

The signature of \mintinline{haskell}`mapAccumBFS` doesn't involve linear types. They are only put into use in the implementation of the \mintinline{haskell}`go` sub-function, as a way to ensure memory safety when using destinations. When \mintinline{haskell}`go` is first called, its argument are the initial state \mintinline{haskell}`s0` and a single-element queue containing a pair of the root of the input tree and a destination for the root of the output tree. Then, during the recursive calls to \mintinline{haskell}`go`, the queue is updated, and linearity enforces the fact that every destination ever put in the queue is eventually filled at some point, which guarantees that the output tree is complete after the function has run, and thus can be made readable.

Because the state-transforming function \mintinline{haskell}`s → a → (s, b)` is non-linear, the leaves of the original tree (that are stored together with destinations in the queue) won't be consumed in a linear fashion. However, as we said, destinations must be all consumed linearly, and for that to hold, their container must be consumed linearly too. So we need a trick to indicate that one sub-part of the queue is allowed to be consumed non-linearly while the rest of the structure will appeared to be consumed linearly.

This is exactly the role that the \mintinline{haskell}`Ur` wrapper plays. A \mintinline{haskell}`Ur a` will appear to be consumed linearly even if its inner value of type \mintinline{haskell}`a` is consumed non-linearly. But only values coming from a non-linear source can be put wrapped in \mintinline{haskell}`Ur`. More precisely, \mintinline{haskell}`Ur` delimitates areas for non-linear values inside structures that are meant to be handled linearly, and only values already wrapped in \mintinline{haskell}`Ur` or coming from the left of a non-linear function arrow \mintinline{haskell}`→` can be put in another \mintinline{haskell}`Ur`. Destinations always appear on the left of linear function arrows \mintinline{haskell}`⊸`, so they couldn't be wrapped in \mintinline{haskell}`Ur` in an attempt to escape the API safety.

With this example, we show how destinations can be used even in a non-linear setting in order to improve the expressiveness of the base language. This more natural and less convoluted implementation of breadth-first traversal also presents great performance gains compared to other functional implementations. \TODO{Insert benchmark}

\subsection{(Perf) Deserializing from a structured format (S-Expr)}

Derserialization is a very common task in application development, and can become a crucial part of the program performance-wise, when the program in question is meant to be fed with large chunks of serialized data.

Let's focus on a deserializer for S-expressions. S-expresssions are parenthesized lists whose elements are just seperated by spaces. These elements can be of several types: int, string, symbol (a textual token, with no quotes around it, unlike a string), or a list of other S-expressions.

Parsing a S-expression can be done concisely with three mutually recursive functions:
\begin{itemize}
  \item \mintinline{haskell}`parseSExpr` scans the next character, and either dispatches to \mintinline{haskell}`parseSList` if it encounters an opening parenthesis, or to \mintinline{haskell}`parseSString` if it encounters an opening quote, or eventually parses the string into a number or symbol;
  \item \mintinline{haskell}`parseSList` calls \mintinline{haskell}`parseSExpr` to parse the next token, and then calls itself again until reaching a closing parenthesis, accumulating the parsed elements along the way;
  \item \mintinline{haskell}`parseSString` scans the input character by character and accumulates them until reaching a closing quote (taking escape sequences into consideration).
\end{itemize}

\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
parseSExpr :: ByteString → Int → Either ParseError SExpr
parseSExpr bs i = case bs !? i of
  Nothing → Left $ UnexpectedEOFSExpr i
  Just c → case c of
    ')' → Left $ UnexpectedClosingParen i
    '(' → parseSList bs (i + 1) []
    '"' → parseSString bs (i + 1) False []
    _ →
      let tok = extractNextToken bs i -- take chars until delimiter/space
       in if null tok
            then -- c is a (leading) space, skip it and recurse
              parseSExpr bs (i + 1)
            else case parseInt tok of
              Just int → Right $ SInteger (i + length tok - 1) int
              Nothing → Right $ SSymbol (i + length tok - 1) (toString tok)

parseSList :: ByteString → Int → [SExpr] → Either ParseError SExpr
parseSList bs i acc = case bs !? i of
  Nothing → Left $ UnexpectedEOFSList i
  Just c → \cases
    | c == ')' → Right $ SList i (reverse acc)
    | isSpace c → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        Left err → Left err
        Right child → parseSList bs (endPos child + 1) (child : acc)

parseSString :: ByteString → Int → Bool → [Char] → Either ParseError SExpr
parseSString bs i escape acc = case bs !? i of
  Nothing → Left $ UnexpectedEOFSString i
  Just c → case c of
    '"' | not escape → Right $ SString i (reverse acc)
    '\\' | not escape → parseSString bs (i + 1) True acc
    'n' | escape → parseSString bs (i + 1) False ('\n' : acc)
    _ → parseSString bs (i + 1) False (c : acc)
\end{minted}
\caption{Implementation of S-expressions parser without destinations}
\label{table:impl-sexpr-parser-without-dest}
\end{table}

Now, the implementation presented in table~\ref{table:impl-sexpr-parser-without-dest} is already quite efficient for a strict setting. The functions are as tail-recursive as they can be, and they use indexing and slicing into a bytestring ($\mathcal{O}(1)$ operation) instead of potentially allocating a huge number of strings on the heap.

That being said, it is possible to obtain very significative performance gains by using destinations with only very little stylistic changes in the code.

Accumulators of tail-recursive functions just have to be changed into destinations. Instead of writing elements into a list that will be reversed at the end as we did before, the program in the destination style will directly write the elements into their final location.

The current implementation of destination-style programming for Haskell is based on Compact Regions, which have two strong properties that clash with usual Haskell ones. First, strictness is mandatory, and any object written in a compact region will be forced into its normal form. Secondly, all objects from a same region will share the same lifetime. Those properties must be dealbreaker for some use cases, but for a parser, they very advantageous!

Indeed, in a program that consumes raw data and parses it (and for which performance does matter), it's uncommon for a part of the input, in its parsed but unprocessed form, to greatly outlive the rest of it. As a result, treating the deserialized data as a large object with a unique lifetime for all its parts is a decent approximation that then allows easier memory management, and as a result impressive garbage collection gains!

As for strictness, most of the time, the result of deserialization will be a data tree, with hundred of nodes and leaves, whose consumption by the processing program will be strict because:
\begin{itemize}
  \item the programmer wants to catch any potential error in the input document early enough in the process;
  \item most of the input will be read to produce the output anyway.
\end{itemize}

All things considered, the properties imposed by the use of destinations seem very compatible with a parsing use-case.

It is good to note that destination allow to reverse the natural order in which a structure is built. For a list, the natural operation in functional programming languages is \emph{prepend}/\emph{cons}, which adds an element at the front of an existing list (bottom-up approach). Thanks to destinations, it's possible to build a list starting from an element which will stay at the head of the it, and new elements will be added towards the tail of the list (\emph{append}/\emph{fillCons}). It's entirely possible to mix both approaches too, as it will be detailed in the API section.

Let's focus on the implementation using destinations, which is presented in table~\ref{table:impl-sexpr-parser-with-dest}:

\newcommand{\mnew}[1]{\colorbox{green}{#1}}
\newcommand{\mold}[1]{\colorbox{red}{\sout{#1}}}

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt,linenos,escapeinside=°°]{haskell}
parseSExprDS :: ByteString → Int → Dest SExpr ⊸ Either ParseError Int
parseSExprDS bs i d = case bs !? i of
  Nothing → °\mnew{d & fillLeaf defaultSExpr}° ;; Left $ UnexpectedEOFSExpr i
  Just c → case c of
    ')' → °\mnew{d & fillLeaf defaultSExpr}° ;; Left $ UnexpectedClosingParen i
    '(' → parseSListDS bs (i + 1) °\mnew{(d & fill @'SList)}\mold{[]}°
    '"' → parseSStringDS bs (i + 1) False °\mnew{(d & fill @'SString)}\mold{[]}°
    _ →
      let tok = extractNextToken bs i -- take chars until delimiter/space
        in if null tok
            then -- c is a (leading) space, skip it and recurse
              parseSExprDS bs (i + 1) d
            else case parseInt tok of
              Just int →
                °\mnew{d & fill @'SInteger & fillLeaf int}°
                  ;; Right (i + length tok - 1)
              _ →
                °\mnew{d & fill @'SSymbol & fillLeaf (toString tok)}°
                  ;; Right (i + length tok - 1)

parseSListDS :: ByteString → Int → Dest [SExpr] ⊸ Either ParseError Int
parseSListDS bs i d = case bs !? i of
  Nothing → °\mnew{d & fill @'[]}° ;; Left $ UnexpectedEOFSList i
  Just c →
    \cases
      | c == ')' → °\mnew{d & fill @'[]}° ;; Right i°\mold{(reverse acc)}°
      | isSpace c → parseSListDS bs (i + 1) d
      | otherwise →
          let !(dh, dt) = °\mnew{d & fill @'(:)}°
          in case parseSExprDS bs i °\mnew{dh}° of
                Left err → dt & fill @'[] ;; Left err
                Right endPos → parseSListDS bs (endPos + 1) °\mnew{dt}\mold{(child : acc)}°

parseSStringDS :: ByteString → Int → Bool → Dest [Char] ⊸ Either ParseError Int
parseSStringDS bs i escape d = case bs !? i of
  Nothing → °\mnew{d & fill @'[]}° ;; Left $ UnexpectedEOFSString i
  Just c → case c of
    '"' | not escape → °\mnew{d & fill @'[]}° ;; Right i°\mold{(reverse acc)}°
    '\\' | not escape → parseSStringDS bs (i + 1) True d
    'n' | escape →
        let !(dh, dt) = °\mnew{d & fill @'(:)}°
         in °\mnew{dh & fillLeaf '\textbackslash{}n'}° ;; parseSStringDS bs (i + 1) False °\mnew{dt}\mold{('\textbackslash{}n' : acc)}°
    _ →
        let !(dh, dt) = °\mnew{d & fill @'(:)}°
         in °\mnew{dh & fillLeaf c}° ;; parseSStringDS bs (i + 1) False °\mnew{dt}\mold{(c : acc)}°
\end{minted}
\caption{Implementation of S-expressions parser with destinations}
\label{table:impl-sexpr-parser-with-dest}
\end{table}

\begin{itemize}
  \item Even for error cases, we are forced to consume the destination that we receive as an argument, hence we write some sensible default data to it (see lines 3, 5, 23 and 36)
  \item Because of the top-down approach, it's necessary to choose which variant of SExpr is being built very early (by writing the corresponding constructor into the \mintinline{haskell}`SExpr` destination), instead of building an accumulator and wrapping the variant constructor over it as it was done in the naive implementation (see lines 6 and 7);
  \item The SExpr value resulting from the call of \mintinline{haskell}`parseSExpr` inside \mintinline{haskell}`parseSList` is no longer collected by the caller; but instead written directly into its final location by the callee (see lines 30 to 32).
  \item Adding an element \mintinline{haskell}`a` to the accumulator \mintinline{haskell}`[a]` is replaced with adding a new cons cell with \mintinline{haskell}`fill @'(:)`, writing the element to the head destination (\mintinline{haskell}`Dest a`), and then continuing the processing with the tail destination (\mintinline{haskell}`Dest [a]`) (see lines 29, 32, 42 and 45).
  \item Instead of reversing and returning the accumulator at the end of the processing, it is enough to complete the list by writing a nil element to the tail destination (with \mintinline{haskell}`fill @'[]`) (see lines 26 and 38).
\end{itemize}

Thanks to that new implementation, the program runs almost twice as fast as the previous one, mostly because garbage-collection time goes to almost zero. The detailed benchmark is available in section [INSERT SECTION].

\section{Technical development}\label{sec:api}

\subsection{API Design}

A destination represents a hole in a data structure, and allows for that hole to be filled even if the 

The main design principle behind destination-style structure building is that no structure can be read before all its destinations have been written to. That way, incomplete data structures can be freely passed around and stored, but need to be completed before any pattern-matching can be made on them.

Hence we introduce a new data type \mintinline{haskell}`Incomplete r a b` where \mintinline{haskell}`a` stands for the type of the structure being built, and \mintinline{haskell}`b` is the type of what needs to be linearly consumed before the structure can be read.

Types aren't linear by themselves in Linear Haskell. Instead, functions can be made linear or not, and linearity of resources are ensured through scope-functions: functions taking a callback that linearly consumes the resource (very much like continuation-passing style).

TODO: Il faut que le seul moyen d'avoir resource en position positive soit en CPS avec callback linéaire (ou dans des fonctions qui ont une resource en position négative aussi)

Let's make things clearer with an example:
{\small
\begin{minted}{haskell}
data Resource

withResource :: (Resource ⊸ a) ⊸ a
\end{minted}
}

If \mintinline{haskell}`withResource` is the only producer of \mintinline{haskell}`Resource`, then the only way to ever access a resource will be to supply a linear callback to \mintinline{haskell}`withResource`. Still, this is not enough; because \mintinline{haskell}`\x → x` is indeed a linear callback, one could use \mintinline{haskell}`withResource (\x → x)` to leak a \mintinline{haskell}`Resource`, and then use it in a non-linear fashion.

We must force the callback to actually consume the resource, and not leak it to the outside. To forbid the resource from appearing anywhere in the return type of the callback, we will ask the return type to be wrapped in \mintinline{haskell}`Ur`. Putting something in \mintinline{haskell}`Ur` is a non-linear operation, except for \mintinline{haskell}`Movable` types, which are basic ones (\mintinline{haskell}`Int`, \mintinline{haskell}`String`, \mintinline{haskell}`Char`...) and structures made of them. As linear resource is simply a data structure which doesn't implement \mintinline{haskell}`Movable`, and which cannot be wrapped linearly in \mintinline{haskell}`Ur`.

With the following declaration, our linear resource cannot leak to the outside world, and must be consumed linearly by the callback (using other functions supplied by the API, written in direct style this time):
{\small
\begin{minted}{haskell}
class Movable a where
  move :: a ⊸ Ur a

data Resource

withResource :: (Resource ⊸ Ur a) → Ur a
updateResource :: Int ⊸ Resource ⊸ Resource
closeResource :: Resources ⊸ ()

-- OK
withResource (\r → r & updateResource 42 & closeResource & move) :: Ur ()

-- fails with linearity error
withResource (\r → r & move) :: Ur Resource
\end{minted}
}

\begin{table}[t]
\small
\begin{minted}[frame=single,framesep=10pt]{haskell}
data RegionToken r
instance Consumable (RegionToken r) where
  consume :: RegionToken r ⊸ ()
instance Dupable (RegionToken r) where
  dup2 :: RegionToken r ⊸ (RegionToken r, RegionToken r)

withRegion :: ∀ a. (∀ r. (RegionContext r) ⇒ RegionToken r ⊸ Ur a) ⊸ Ur a

data Incomplete r a b
instance Control.Functor (Incomplete r a) where
  fmap :: ∀ b c. (b ⊸ c) ⊸ Incomplete r a b ⊸ Incomplete r b c

intoRegion :: ∀ r a. RegionToken r ⊸ a → Incomplete r a ()
fromRegion :: ∀ r a. (RegionContext r) ⇒ Incomplete r a () ⊸ Ur a
fromRegionExtract :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a (Ur b) ⊸ Ur (a, b)

data Dest r a
type family DestsOf liftedCtor r a -- computes dests associated to fields of a constructor

alloc :: ∀ r a. RegionToken r ⊸ Incomplete r a (Dest r a)

fill :: Dest r a → DestsOf liftedCtor r a
fillComp :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a b ⊸ Dest r a ⊸ b
fillLeaf :: ∀ r a. (RegionContext r) ⇒ a → Dest r a ⊸ ()
\end{minted}
\caption{Destination for Haskell API}
\label{table:destination-api}
\end{table}

This is mostly the design principle that have been used for destinations in Haskell. In order to access the \mintinline{haskell}`Incomplete`'s \mintinline{haskell}`a` value, the \mintinline{haskell}`b` side must be transformed/consumed into something with type \mintinline{haskell}`Ur c`. Because the \mintinline{haskell}`b` side hosts the destinations initially, they have to be consumed by a linear callback mapping on \mintinline{haskell}`b` side before \mintinline{haskell}`fromRegion` can be used to access the \mintinline{haskell}`a`. As we explained above, they cannot leak as there is no linear way to produce a \mintinline{haskell}`Ur Dest` from a \mintinline{haskell}`Dest`.

An overview of the whole API is presented in table~\ref{table:destination-api}.

\mintinline{haskell}`Region`, \mintinline{haskell}`RegionContext r` and \mintinline{haskell}`RegionToken r` are mostly implementation noise for the API. There presence will be justified in the next subsection.

Allocation a new receiver of type \mintinline{haskell}`a` is done through \mintinline{haskell}`alloc`:

{\small
\begin{minted}{haskell}
alloc :: ∀ r a. RegionToken r ⊸ Incomplete r a (Dest r a)
\end{minted}
}

This function signature can be read that way : it consumes a region token, and returns an object holder, which upon consumption of a \mintinline{haskell}`Dest r a`, will unlock the object of type \mintinline{haskell}`a`. At this point, the return value of `alloc` is pretty much the identity: give it an \mintinline{haskell}`a` (to fill the \mintinline{haskell}`Dest r a`), and it will return an \mintinline{haskell}`a`.

Manipulating an \mintinline{haskell}`Incomplete` object is done through its \mintinline{haskell}`Functor` instance, which allows to map over the side which initially contains the root destination:

{\small
\begin{minted}{haskell}
newtype Incomplete r a b = Incomplete (a, b)

instance Control.Functor (Incomplete r a) where
  fmap :: (b ⊸ c) ⊸ Incomplete r a b ⊸ Incomplete r b c
  fmap f (Incomplete (s, d)) = Incomplete (s, f d)
\end{minted}
}

To fill a hole represented by \mintinline{haskell}`Dest r a`, several functions are available:

\begin{itemize}
  \item \mintinline{haskell}`fillLeaf :: ∀ r a. (RegionContext r) ⇒ a → Dest r a ⊸ ()` \\will use a non-linear value of type \mintinline{haskell}`a` to fill the hole;
  \item \mintinline{haskell}`fillComp :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a b ⊸ Dest r a ⊸ b` \\will use an incomplete object of type \mintinline{haskell}`a` to fill the hole; and the resulting holes for the bigger structure will be the ones of that object. In other terms, \mintinline{haskell}`fillComp` composes two structures with holes together;
  \item \mintinline{haskell}`fill :: ∀ liftedCtor r a. Dest r a ⊸ DestsOf liftedCtor r a` \\takes a constructor as a type parameter (\mintinline{haskell}`liftedCtor`) and will write a hollow instance of that constructor into the \mintinline{haskell}`Dest r a`, returning the destinations corresponding to that constructor's fields.\\ For example, \mintinline{haskell}`fill @Just @r @(Maybe Int) :: Dest r (Maybe Int) ⊸ Dest r Int` writes a hollow \mintinline{haskell}`Just` constructor in the \mintinline{haskell}`Maybe Int` hole, and returns the \mintinline{haskell}`Dest Int` corresponding to the hole of type \mintinline{haskell}`Int` that still needs to be filled.
\end{itemize}

\mintinline{haskell}`fill` is probably the most interesting of the three, and will be the most used one too, because it enables the user to build data structures in a top-down approach, which complements very well the natural bottom-up way of constructing data structures in functional programming languages. Thanks to destinations, the user can now choose between those two approaches and pick the most efficient or more natural way for the problem at hand.

\mintinline{haskell}`fillComp` offers a way to mix both approaches: one can build small chunks in a top-down approach, and combine them together in a bottom-up fashion even if they aren't all complete.

\mintinline{haskell}`fillLeaf` is just a restriction of \mintinline{haskell}`fillComp`. It is used very frequently for types whose constructors aren't \mintinline{haskell}`Fill`able because they wrap over unpacked or primitive fields.

\subsection{Note about Compact Regions}

TODO: + précis; linker papier, expliquer que historiquement pour but sérialisation, préciser fonctionnement précis vis à vis du GC
TODO: rôle des compact regions ajd: GC savings pour données long-lived (exemple cache Arnaud) → Ici on pousse ce mécanisme plus loin

At the moment, destination-style programming is only possible in compact regions. Compact regions are special chunks on the heap that will only be very lightly inspected by the garbage collector, and thanks to that, we can do chirurgical memory updates in those without being afraid that it will interfere with garbage collection (especially move operations).

Because we have immobile chunks of memory, destinations can be implemented as a wrapper over a raw pointer which points to the memory location where data have to be written:

{\small
\begin{minted}{haskell}
data Dest r a = Dest Addr#
\end{minted}
}

The phantom type parameter \mintinline{haskell}`r` that is present everywhere in the API ensures that objects can only interact with other ones from the same region (as outgoing pointers across different regions are not allowed by design of Compact regions).

A \mintinline{haskell}`Region` object is implemented as a newtype over \mintinline{haskell}`Compact FirstInhabitant`, which is composed of a pointer to the region header, a lock (because compact region writes are not thread-safe at the primitive level), and a pointer to a \mintinline{haskell}`FirstInhabitant` inside the region.

\mintinline{haskell}`RegionToken r` carries a non-linear \mintinline{haskell}`Region` and is used when a \mintinline{haskell}`Proxy r` would be necessary anyway to infer the \mintinline{haskell}`r` of \mintinline{haskell}`Dest`/\mintinline{haskell}`Incomplete` in a function signature. \mintinline{haskell}`RegionContext r` makes the region argument implicit when the region identifier \mintinline{haskell}`r` is already part of the types of the function arguments.

\subsection{User-land haskell implementation details}
 
One issue I had during implementation was choosing the right representation for \mintinline{haskell}`a` in \mintinline{haskell}`Incomplete r a b`.

Ideally, we want \mintinline{haskell}`Incomplete r a b` to contains a \mintinline{haskell}`a` and a \mintinline{haskell}`b`, and let the \mintinline{haskell}`a` free when the \mintinline{haskell}`b` is fully consumed (or linearly transformed into \mintinline{haskell}`Ur c`). So the most straightforward representation of Incomplete would be a pair \mintinline{haskell}`data Incomplete r a b = Incomplete a b`.

It is also natural for \mintinline{haskell}`alloc` to return an \mintinline{haskell}`Incomplete r a (Dest a)`: as soon as the \mintinline{haskell}`Dest a` is linearly consumed, a \mintinline{haskell}`a` will be available.

However, building something of type \mintinline{haskell}`Incomplete r a (Dest a)` is not easy. The \mintinline{haskell}`Dest a` in question should carry the address of a memory cell in which the address of a constructor of type \mintinline{haskell}`a` will be written (by \mintinline{haskell}`fill` or a similar function). That memory cell is named \emph{root receiver}, because it will receive the address of the root of the object being built. Given the data definition above, the root receiver should hence be the first field of the \mintinline{haskell}`Incomplete` object. But the Incomplete object is not part of the compact region itself! It lives in the normal GC heap (which is crucial for early deallocation and memory optimizations); so it may move. As a result, we cannot just use the address of its left field as a destination and the left field as a root receiver.

The next natural move is to allocate a wrapper \mintinline{haskell}`W a` for \mintinline{haskell}`a` in the region, that will act as a root receiver, and have \mintinline{haskell}`data Incomplete r a b = Incomplete (W a) b`. Because the \mintinline{haskell}`a` will have to be wrapped in \mintinline{haskell}`Ur` when it is complete (see \mintinline{haskell}`fromRegion :: ∀ r a. (RegionContext r) ⇒ Incomplete r a () ⊸ Ur a`), we might as well use \mintinline{haskell}`Ur` as a wrapper and declare \mintinline{haskell}`data Incomplete r a b = Incomplete (Ur a) b`. It solves the previous issue of not having a receiver to write into.

Unfortunately, that approach is quite unsatisfying because any \mintinline{haskell}`Incomplete` object will now allocate a few words into the region that won't be collected for a long time. In particular, putting a non-linear value inside the region with \mintinline{haskell}`intoRegion :: ∀ r a. RegionToken r ⊸ a → Incomplete r a ()` will allocate an unnecessary \mintinline{haskell}`Ur` wrapper, as the object is already fully built, and thus doesn't need a root receiver. With the \mintinline{haskell}`Ur` solution, it's no longer efficient to write \mintinline{haskell}`fillLeaf` as a composition \mintinline{haskell}`fillComp . intoRegion (getToken @r)`, and \mintinline{haskell}`fillLeaf` needs a dedicated optimized implementation.

Another approach we explored is to represent an \mintinline{haskell}`Incomplete` as a piece of data structure that would be concretized when it is given a root receiver. Delaying the construction of the structure that way is not efficient though, because instead of writing a structure to memory, we create huge closures representing the action of creating the structure.

Finally, I decided to embed the \mintinline{haskell}`a` field in \mintinline{haskell}`Incomplete` not in a regular data constructor wrapper, but instead in a STG indirection closure (\mintinline{haskell}`stg_IND` symbol). The indirection closure is allocated into the compact region in the \mintinline{haskell}`alloc` case (for the same reasons as the \mintinline{haskell}`Ur` above was), but no indirection closure is needed in \mintinline{haskell}`intoRegion`, we can just store the fully built \mintinline{haskell}`a` directly in \mintinline{haskell}`Incomplete`. That way, we keep uniformity in the typing and runtime behaviour of \mintinline{haskell}`Incomplete` in both cases (as indirections are transparent for the RTS), and ensure that the overhead of `fillLeaf`/\mintinline{haskell}`intoRegion` is very small, at the cost of a few more alloc-ed words for each call of \mintinline{haskell}`alloc`. This is a fair price to pay because any real-world program should call \mintinline{haskell}`fillLeaf` way more than \mintinline{haskell}`alloc` (which is only required to create the root of a new big object).

The implementation of \mintinline{haskell}`fromRegion` and \mintinline{haskell}`fromRegionExtract` is then relatively straightforward. \mintinline{haskell}`fromRegion :: ∀ r a. (RegionContext r) ⇒ Incomplete r a () ⊸ Ur a` discards the \mintinline{haskell}`()` value carried by the Incomplete, allocates a \mintinline{haskell}`Ur _` in the region, writes the address of the \mintinline{haskell}`a` value into the \mintinline{haskell}`Ur` slot, and returns it. \mintinline{haskell}`fromRegionExtract :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a (Ur b) ⊸ Ur (a, b)` allocates a \mintinline{haskell}`Ur (_, _)` into the region, checks whether the \mintinline{haskell}`b` in \mintinline{haskell}`Ur b` is already part of the region or not (and copies it into the region if it isn't), and writes the address of the \mintinline{haskell}`a` and \mintinline{haskell}`b` values into the slots of the \mintinline{haskell}`Ur`ed pair before returning it.

\paragraph{Deriving \mintinline{haskell}`Fill` for all datatypes with `Generics`}

The \mintinline{haskell}`Fill liftedCtor r a` class has only one method, \mintinline{haskell}`fill :: Dest r a → DestsOf liftedCtor r a`.

As it has been said before, the action of \mintinline{haskell}`fill @liftedCtor @r @a` is to allocate a new hollow constructor \mintinline{haskell}`Ctor _ :: a` in the region, and fill a destination of type \mintinline{haskell}`Dest r a` with its address. Because the constructor is hollow (i.e. its fields haven't been initialized), \mintinline{haskell}`fill` should also return destination objects pointing to these incomplete fields a.k.a. holes.

The type of the destinations that should be returned by \mintinline{haskell}`fill` can be computed by carefully inspecting the \mintinline{haskell}`Generic` representation of the type \mintinline{haskell}`a`. Indeed, GHC.Generics is a haskell library that provides compile-time inspection of a type metadata (list of constructors, fields, memory representation...) if the type implements the \mintinline{haskell}`Generic` class. Fortunately, the implementation of the \mintinline{haskell}`Generic` class be derived automatically by the compiler (instead of being implemented manually), making it easy to use for user-defined types.

In the \mintinline{haskell}`DestsOf` type family and in in the different \mintinline{haskell}`Fill` instance heads, I inspect the \mintinline{haskell}`Generic` representation of the given type \mintinline{haskell}`a` to find the metadata of the constructor whose lifted representation is \mintinline{haskell}`liftedCtor`, and then I extract the number of fields of the constructor and their types.

For example, the \mintinline{haskell}`Generic representation` of \mintinline{haskell}`Maybe a` gives

{\small
\begin{minted}[escapeinside=°°]{haskell}
M1 D (MetaData "Maybe" "GHC.Maybe" "base" False) (
  M1 C (MetaCons "Nothing" PrefixI False) U1
  :+: M1 C (MetaCons "Just" PrefixI False) (M1 S [...] (K1 R a)))
\end{minted}
}

indicating that there is zero fields with constructor \mintinline{haskell}`Nothing` and one field of type \mintinline{haskell}`a` with constructor \mintinline{haskell}`Just`. 


The representation for \mintinline{haskell}`(a, b)` gives

{\small
\begin{minted}[escapeinside=°°]{haskell}
  M1 D (MetaData "Tuple2" "GHC.Tuple.Prim" "ghc-prim" False) (
    (M1 C (MetaCons "(,)" PrefixI False) (
      M1 S [...] (K1 R a)
      :*: M1 S (K1 R b))))
\end{minted}
}

indicating that there are two fields, one of type \mintinline{haskell}`a` and one of type \mintinline{haskell}`b`, with the \mintinline{haskell}`(,)` data constructor.

Fields of a constructor are stored contiguously in memory, at offset $i \times \textit{wordsize}_{(i \in 1..n)}$ from the constructor base address. So \mintinline{haskell}`fill` just harvests the field metadata and can easily build as many destinations as there are fields, using the address of the newly allocated constructor as a base point. The extracted types of the fields are used to specify the phantom type parameter of the destinations.

\subsection{Changes to GHC's internals and RTS}

The implementation we described in the previous parts relies on being able to allocate hollow constructors. This is the key point of destination-style programming: building structures in a top-down approach, where nodes deeper in the data tree are left unspecified for some time.

Usually, in Haskell, every field must be explicitly specified to allocate a constructor closure. This definitely makes sense as there is no (safe) way to later update a field in a mutable/in-place fashion; so an unspecified field would stay unspecified forever.

Of course, it is possible to overcome that well-founded rule by using a unique \emph{joker value} for every field of a constructor: \mintinline{haskell}`Right undefined` or \mintinline{haskell}`(undefined, undefined)` are valid haskell values that shouldn't blow up too fast. Using an unsafe coercion works too: \mintinline{haskell}`(unsafeCoerce (), unsafeCoerce ()) :: (a, b)` is valid. Theoretically, we hence have a way to allocate a somewhat hollow constructor.

That being said, there is no primitive in GHC at the moment that allows to allocate a value directly in a compact region. The only way to put something in a region is to copy something that has already been allocated in the normal GC heap. So even with the trick described above, the constructor closure would need to be allocated twice.

As a result, in order to obtain the maximum performance and memory gains from the use of destination, I had no other choice than to tweak the GHC compiler and add a new primitive operation (\emph{primop}) in charge of allocating a hollow constructor directly into a compact region.

\paragraph{About GHC architecture, RTS and primops}

GHC is the main compiler for the Haskell programming language, and its compilation model involves several intermediary languages.

First, Haskell code is turned into Core, a typed language whose syntax is mostly a subset of Haskell one. A lot of Haskell constructs are desugared into constructors and case expressions, type applications are made explicit, etc.
Then, several optimization steps are made on the Core output, like removing case expressions on known constructors, or floating \mintinline{haskell}`let` expressions (moving them upwards in the code to factor out some computations).

When all Core optimizations have been made, Core code is then transformed into STG code. In STG, all memory objects (called \emph{closures}) have the same memory representation, in the form of a pointer to a struct called the \emph{info table}, and a payload of a variable size (composed of primitive values and pointers to other closures). Because Haskell works in a lazy fashion, closures might not represent evaluated values, so the info table of each closure contains a pointer to a block of code that is responsible for evaluating the sub-expression that the closure represents. In other terms, the caller is not responsible for knowing how to evaluate the closure, but the closure itself is.
As you can imagine, having a dedicated info table with each closure would be excessively expensive memory-wise (as both of them would need to be dynamically allocated). Instead, the STG uses sharing as most as possible, and for example, every dynamic closure representing the constructor application of a given constructor (let's say \mintinline{haskell}`Just`) will have the same info table pointer, pointing to a single statically-allocated info table. Indeed, no matter what type of argument it is applied to, every \mintinline{haskell}`Just` instance will have the same memory layout (only one boxed argument as a payload), and the same evaluation code (doing nothing and returning immediately because a constructor application is already in weak-head normal form). That kind of sharing in fact quite common in other programming languages too: virtual tables are shared in the same way in C++.

Other specific info tables are also being shared in the STG: the ones for "blackholes" (which is used to indicate that a closure is currently under evaluation by a thread and that its result is still pending); the ones for indirection, etc.

All that sharing is made through the use of labels:

\begin{itemize}

\item when the declaration of a data constructor is encountered (definition site), the corresponding info table is emitted to the static area of the output program, and its address is associated with the label \mintinline{haskell}`<constructor name>_con_info`
\item when the use of a data constructor is encountered, the label \mintinline{haskell}`<constructor name>_con_info` is used in place of an actual address in the closure that is emitted
\item later on in the compilation process, those labels will be converted by the linker into actual addresses

\end{itemize}

Now, the runtime behaviour of a Haskell program is directed by the \emph{run-time system}, or RTS, which is a software component written in a mix of C and C-- (the last language in the compilation pipeline of Haskell for a native build). The RTS is built once for all when GHC itself is being built, and it is then included in every executable produced by GHC.

Its role is to manage threads, organize garbage collection and also to manage compact regions (among other things). The RTS defines various primops that allow the haskell programmer to interact with it for those needs. For example, \mintinline{haskell}`compactAdd#` is the primitive operation that copies a closure into an existing compact region, fully evaluating its potentiel sub-expressions along the way.

There are also primops in GHC which are meant to be resolved at the \emph{Core to Stg} phase (emitting some code at compile time), but which don't trigger any specific interaction with the RTS at runtime. Among those are all the primitive numeric operators on primitive types (\mintinline{haskell}`+#`, \mintinline{haskell}`-#`...), and more generally all the performance-critical operations working on unboxed types, and which don't require any specific interaction or precaution with garbage collection or thread execution, or don't need a specific allocation scheme, etc.

It is important to note for the next of that part that the RTS cannot really access information that would have been made available during the compilation of a specific haskell program. Indeed, the RTS included in the final executable for the given program is the same as the one included in all other executables made with the same version of GHC ; it isn't possible to parametrize the RTS with data collected during the compilation of the given program (ex: types used or defined in the program). The only data channel I found between the compilation stage of a program and the RTS is to reify the needed compile-time information into a runtime value that will later be passed to the RTS through a primop call.

\paragraph{New primops to support destination-style programming}

What I want to do is twofold:
\begin{itemize}
\item First, add a primop to the RTS to allocate space into a compact region for a hollow constructor ;
\item Second, add a non-RTS primop to reify the necessary information about a constructor into a runtime-value so that it can be communicated to the RTS (because the RTS cannot access that itself, as I explained above)
\end{itemize}

The first step mostly takes place in \mintinline{text}`rts/Compact.cmm`, the main C-- module of the RTS for compact regions management, as presented in table~\ref{table:impl-compactAddHollow}.

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt]{c}
// compactAddHollow# :: Compact# → Addr# → State# RealWorld → (# State# RealWorld, a #)
stg_compactAddHollowzh(P_ compact, W_ info)
{
    W_ pp, ptrs, nptrs, size, tag, hp;
    P_ to, p;
    again: MAYBE_GC(again);
    STK_CHK_GEN();

    pp = compact + SIZEOF_StgHeader + OFFSET_StgCompactNFData_result;
    ptrs  = TO_W_(%INFO_PTRS(%STD_INFO(info)));
    nptrs  = TO_W_(%INFO_NPTRS(%STD_INFO(info)));
    size = BYTES_TO_WDS(SIZEOF_StgHeader) + ptrs + nptrs;
    p = NULL;  // p isn't actually used by ALLOCATE macro

    ALLOCATE(compact, size, p, to, tag);
    P_[pp] = to;
    SET_HDR(to, info, CCS_SYSTEM);
#if defined(DEBUG)
    ccall verifyCompact(compact);
#endif
    return (P_[pp]);
}
\end{minted}
\caption{Implementation of \texttt{compactAddHollow\#} in the RTS}
\label{table:impl-compactAddHollow}
\end{table}

The \mintinline{c}`stg_compactAddHollowzh` function is mostly a glorified call to the \mintinline{haskell}`ALLOCATE` macro defined in the same file, which tries to do a pointer-bumping alloc in the current block of the compact region if there is enough space, and otherwise add a new block to the region.

As we said earlier, \mintinline{haskell}`stg_compactAddHollowzh`/\mintinline{haskell}`compactAddHollow#` needs to access the info table pointer of the constructor we want to allocate, but cannot do so directly as the RTS cannot access STG labels. This is why the function must receive a \mintinline{haskell}`info` parameter of type \mintinline{haskell}`W_`/\mintinline{haskell}`Addr#` (the former is the C-- type; the latter is the Haskell one).

Let's see how to reify the info table pointer of a constructor into a runtime value now. We want to add a new primitive operation in GHC that takes a compile-time-known string or constructor as input and compiles down to the label having that name or corresponding to the constructor's info table pointer.

In Haskell, compile-time-known strings are represented by a type-level string literal of kind \mintinline{haskell}`Symbol`, and constructors can be lifted into type literals as well (with \mintinline{haskell}`LANGUAGE DataKinds` and prefixing the constructor with \mintinline{haskell}`'`, e.g. \mintinline{haskell}`'Just`). So the function we would like to build must have a type parameter somewhere, probably in one of its argument types, corresponding to that type-level literal input, like \mintinline{haskell}`reifyStgInfoPtr# :: Proxy# s → Addr#` (where \mintinline{haskell}`s` would stand for the lifted constructor or symbol).

The problem is, the compilation pipeline only start emitting labels at the \emph{STG to C--} phase. And at that point, almost all type information for polymorphic primops' parameters have been erased. Fortunately, for some technical reason, information about the actual return type of a primop is retained that late in the compilation process.

Here's the trick I used so: I built a dedicated return type for \mintinline{haskell}`reifyStgInfoPtr#`, namely \mintinline{haskell}`InfoPtrPlaceholder# a`. That type has a phantom type parameter but shares the same memory representation as \mintinline{haskell}`Addr#`. That way, it is possible to use a type hint to provide the type-level literal to the primop: \mintinline{haskell}`reifyStgInfoPtr# (# #) :: InfoPtrPlaceholder# a` will allow the implementation of \mintinline{haskell}`reifyStgInfoPtr#` to read the type parameter \mintinline{haskell}`a` even though it is both phantom and in return position.

The gist of this implementation is presented in table~\ref{table:impl-reifyStgInfoPtr}, which we will now comment a bit.

\begin{table}[H]
\small
\begin{minted}[frame=single,framesep=10pt,linenos]{haskell}
case primop of
  [...]
  ReifyStgInfoPtrOp → \_ →  -- we don't care about the function argument (# #)
    opIntoRegsTy $ \[res] resTy → emitAssign (CmmLocal res) $ case resTy of
      -- matches when 'a' is a Symbol, and extracts the symbol value as a FastString in 'sym'
      TyConApp _addrLikeTyCon [_typeParamKind, LitTy (StrTyLit sym)] →
        CmmLit (CmmLabel (mkCmmInfoLabel rtsUnitId (fsLit "stg_" `appendFS` sym)))
      -- matches when 'a' is a lifted data constructor, and extracts it as a DataCon (from GHC.Core.DataCon)
      TyConApp _addrLikeTyCon [_typeParamKind, TyConApp tyCon _] | Just dataCon <- isPromotedDataCon_maybe tyCon → do
        CmmLit (CmmLabel (mkConInfoTableLabel (dataConName dataCon) DefinitionSite))
      -- return garbage data when no pattern matches
      _ → [...]
  [...]
\end{minted}
\caption{Implementation of \texttt{reifyStgInfoPtr\#} in GHC}
\label{table:impl-reifyStgInfoPtr}
\end{table}

Going from the \mintinline{haskell}`InfoPtrPlaceholder# a` returned by \mintinline{haskell}`reifyStgInfoPtr#` to an actual \mintinline{haskell}`Addr#` is just a matter of calling the \mintinline{haskell}`unsafeCoerceAddr` function supplied by GHC, as both type are represented by pointers/addresses under the hood.

With both primops in hand, we can allocate a hollow constructor closure directly in a compact region in an efficient fashion. For example, for \mintinline{haskell}`Just`, one should do:
{\small
\begin{minted}{haskell}
hollowJust :: Maybe a
hollowJust = compactAddHollow#
  compactRegion#
  (unsafeCoerceAddr (reifyStgInfoPtr# (# #) :: InfoPtrPlaceholder# 'Just))  
\end{minted}
}

It would probably be possible to merge the two primops into a two-stage one (with both a compile-time and run-time action) without too much effort.

\paragraph{Destination-style programming with stock GHC}

During the early days of my research, I first experimented with hollow allocation without any modification to GHC codebase. Instead of using the primops I described above, I made heavy use of runtime heap inspection and \mintinline{haskell}`GHC.Generics` trickery to build hollow constructors with the correct info table pointers. As a result, it is still possible to use destinations-style programming without using a patched version of GHC, but performance gains are not guaranteed in that context.

TODO: si temps restant, comparer les performances

\section{Evaluating performance of destination-style programming}

\subsection{Benchmarking / profiling strategy}

Benchmarking code using destination hasn't been easy.

First, the current implementation of destinations for Haskell uses compact regions, which force strictness "for free", whereas regular Haskell code is lazy by default; and thus the produced data structures need to be explicitly forced into normal form.

There are two main ways to force a structure into normal form. The first one is to use the tools supplied by the \mintinline{haskell}`deepseq` package. That packages defines a typeclass, \mintinline{haskell}`NFData`, which can be easily derived for user-defined datatypes, which in turn gives access to functions like `force' or `rnf' that will force every thunk (pending lazy computation) from a value/structure. Using \mintinline{haskell}`deepseq` to benchmark the naive implementation (the one without destinations) has the advantage of not making unnecessary allocations, so the reported memory usage is accurate, but the \emph{forcing} operation might incur extra CPU usage and thus slow the program down, because forcing thunk artificially with \mintinline{haskell}`force` or \mintinline{haskell}`rnf` is not as efficient as if they were forced in an organic way by the RTS during the program execution.

The second way to force a lazy structure into normal form is to copy it into a compact region. Indeed, the \mintinline{haskell}`compact`/\mintinline{haskell}`compactAdd` functions from \mintinline{haskell}`GHC.Compact` will efficiently force every thunk of a structure before writing their final value into the region. Most of the time, using \mintinline{haskell}`compact` is faster than using \mintinline{haskell}`force`, as the  \emph{forcing} code is written in C/C-- instead of Haskell, but it creates two issues:

\begin{itemize}
  \item the space allocated in the region for the result is counted towards the total memory allocated by the program. However, compact regions aren't suited for all use-cases. For some of them, the GC gains they would offer wouldn't balance for the extra time during which some garbage will continue to live in memory. As a result, it seems unfair to count the extra memory usage in the region incurred by \mintinline{haskell}`compact` for programs which wouldn't make use of compact regions in normal time (as the result structure is already present in the normal GC heap) ;
  \item \mintinline{haskell}`compact` not only forces all thunks, but also copies their final value into the region. The time required to make the copy, despite being small, is still counted towards the total execution time of the program.
\end{itemize}

To my knowledge, there is no better way than these two to mesure the time taken by a strict program and by a lazy program, in an accurate and fair way.


\begin{itemize}
\item Three modes (-T, -s, -p)
\item How to evaluate naive code (why we use both copyIntoRegion and force)
\end{itemize}

\subsection{Performance of map implementation (in a strict context)}

\begin{itemize}
\item How this is important for Ocaml
\end{itemize}

\subsection{Performance of the SExpr parser}

\subsection{Performance of BFS Tree traversal}

\subsection{Qualitative evaluation of destination code VS naive code}

\begin{itemize}
\item TODO: implement a naive implement of functional mapMBFS
\item \end{itemize}

\section{Conclusion and related work}
\begin{itemize}
\item Why it's an improvement over Minamide

\item Lifting the non-linear restriction for elements stored in dest-allocated structures (= requires more theoretical work)

\item Using destinations in different contexts than compact regions (normal GC heap, other kinds of chunk-allocated memory)
\end{itemize}

\printbibliography

\end{document}
