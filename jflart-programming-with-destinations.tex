\documentclass[english]{jflart}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{minted}
\usepackage{etoolbox,xpatch}
\usepackage{ tipa }
\usepackage[normalem]{ulem}
\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{bibliography.bib}

% Numéro et année des JFLAs visées par l'article, obligatoire.
\jfla{35}{2024}

\title{Programming with destinations in Haskell}
% Un titre plus court, optionnel.
%\titlerunning{Du bon usage de~\texttt{jflart.cls}}

% Auteurs, liste non abrégée.
\author[1]{Thomas Bagrel}
% \author[2]{Cunégonde Martin}
% \author[2]{Odoacre Contempierre}
% Une liste d'auteurs abrégée à utiliser à l'intérieur de l'article.
\authorrunning{Bagrel}

% Affiliations des auteurs
\affil[1]{INRIA/LORIA, Vand\oe{}uvre-lès-Nancy, 54500, France}
\affil[2]{TWEAG, Paris, 75012, France}

% Une commande définie par l'utilisateur
\newcommand{\cmd}[1]{\texttt{\textbackslash {#1}}}
\newcommand{\mpar}{\text{\,\textramshorns\,}}
\newcommand{\dest}{-\prec}
\usepackage{newunicodechar}
\newunicodechar{⊸}{\ensuremath{\multimap}}
\newunicodechar{→}{\ensuremath{\to}}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{∀}{\ensuremath{\forall}}
\makeatletter
\AtBeginEnvironment{minted}{\dontdofcolorbox}
\def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
\xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
\xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{} % see https://tex.stackexchange.com/a/401250/
\makeatother

\begin{document}

\maketitle

\begin{abstract}
Destination-passing style programming introduces destinations, which represents the address of a write-once memory cell. Those destinations can be passed around as function parameters, and thus enable the caller of a function to keep control over memory allocation: the body of the called function will just be responsible of filling that memory cell. This is especially useful in functional programming languages such as Haskell, in which the body of a function is typically responsible for allocation of the result value.

Programming with destination in Haskell is an interesting way to improve performance of critical parts of some programs, without sacrificing memory warranties. Indeed, thanks to a linearly-typed API we designed, a write-once memory cell cannot be left uninitialized before being read, and is still disposed of by the garbage collector when it is not in use anymore, eliminating the risk of uninitialized read, memory leak, or double-free errors that can arise when memory is handled manually.

With the implementation of destinations for Haskell through compact regions we provide in this article, we reach a 15-40\% improvement over memory allocation in a simple parser example, and 0-50\% improvement in run time. We also provide a few examples of programs that can be implemented in a tail-recursive fashion thanks to destinations, which is crucial for performance in strict contexts.

Safety proofs for the API are not provided in this article though, and will be the subject of a future article.
\end{abstract}

\tableofcontents{}

\section{Introduction}

Destinations bring a taste of imperative programming in a pure functional environnement when performance really matters, without breaking memory safety.

Using destinations as a way of allocating and building functional data structures can lead to better time and/or space performance for critical parts of a program, but destinations also increase expressiveness of a functional language.

\subsection{Problem space and motivation}

\subsection{Framework}

- GHC where purity is enforced

- Also because it has good support for linear type discipline

\section{Motivating examples for destination-style programming}

\subsection{(Perf) Efficient Difference-list implementation}

\subsection{(Expressiveness) BFS Tree mapping/traversal}

Traversing a binary tree in a breadth-first fashion with monadic effects is notoriously hard to implement in a pure functional fashion. Indeed, when a node in the resulting tree is produced, we cannot build its children immediately because the effects of the children node creation would break the BFS order. Instead, we must store the path to that node in a queue, and come back much later to add its children, so that BFS effect order is preserved.

With destinations in our toolbelt, the problem is much simpler, as we can just let that node be "incomplete" for the time being, store the destinations for its children in a queue, and fill them later when they reach the head of the queue. There is no need to store the path up to that node in a fancy fashion, and no need to build many temporary functional structures in memory either. In a way, destinations provide a single-use \emph{action-at-a-distance} concept.

\begin{minted}[linenos]{haskell}
data Tree a = Nil | Node a (Tree a) (Tree a)

mapStateBFS :: ∀ a b s. (s → a → (s, b)) → s → Tree a → (s, Tree b)
mapStateBFS f s0 tree =
  buildInRegionAndExtract $
    \token → alloc token <&>
      \dtree → go s0 (singleton (Ur tree, dtree))
  where
    go :: s → Queue (Ur (Tree a), Dest (Tree b)) ⊸ Ur s
    go s q = case dequeue q of
      Nothing → Ur s
      Just ((utree, dtree), q') → case utree of
        Ur Nil → dtree & fill @'Nil `lseq` go s q'
        Ur (Node x tl tr) → case dtree & fill @'Node of
          (dr, dtl, dtr) →
            let q'' = q' `enqueue` (Ur tl, dtl) `enqueue` (Ur tr, dtr)
                (s', r) = f s x
              in dr & fillLeaf r `lseq` go s' q''
\end{minted}

\subsection{(Perf) Deserializing from a structured format (S-Expr)}

Derserialization is a very common task in application development, and can become a crucial part of the program performance-wise, when the program in question is meant to be fed with large chunks of serialized data.

Most of the time, the result of deserialization will be a data tree, with hundred of nodes and leaves, whose consumption by the processing program will be strict because:
\begin{itemize}
  \item the programmer wants to catch any potential error in the input document early enough in the process;
  \item most of the input will be read to produce the output anyway.
\end{itemize}

Also, it's uncommon for a part of the input (in its parsed but unprocessed form) to greatly outlive the rest of it. As a result, treating the deserialized data as a large object with a unique lifetime for all its parts is a decent  approximation when that allows easier memory management, as we will show in a next section.

The current implementation of linear-dest is based on Compact Regions, which bring to the table the two aforementioned properties: strictness, and a shared lifetime for a tree of objects, in exchange of impressive garbage collection savings!

Let's focus on a deserializer for S-expressions. S-expresssions are parenthesized lists whose elements are just seperated by spaces. These elements can be of several types: Int, String, Symbol (a textual token, with no quotes around it, unlike String), or (nested) list.

Parsing a S-expression can be done concisely with three mutually recursive functions:
\begin{itemize}
  \item \mintinline{haskell}`parseSExpr` will scan the next character, and either dispatch to \mintinline{haskell}`parseSList` if it encounters an opening parenthesis, or to \mintinline{haskell}`parseSString` if it encounters an opening quote, or eventually parse the string into a number or symbol ;
  \item \mintinline{haskell}`parseSList` will call \mintinline{haskell}`parseSExpr` to parse the next token, and then call itself again until reaching a closing parenthesis, accumulating the parsed elements along the way ;
  \item \mintinline{haskell}`parseSString` will scans the input character by character and accumulate them until reaching a closing quote (taking escape sequences into consideration).
\end{itemize}

\begin{minted}[linenos]{haskell}
parseSExpr :: ByteString → Int → Either ParseError SExpr
parseSExpr bs i = case bs !? i of
  Nothing → Left $ UnexpectedEOFSExpr i
  Just c → case c of
    ')' → Left $ UnexpectedClosingParen i
    '(' → parseSList bs (i + 1) []
    '"' → parseSString bs (i + 1) False []
    _ →
      let tok = extractNextToken bs i -- take chars until delimiter/space
       in if null tok
            then -- c is a (leading) space, skip it and recurse
              parseSExpr bs (i + 1)
            else case parseInt tok of
              Just int → Right $ SInteger (i + length tok - 1) int
              Nothing → Right $ SSymbol (i + length tok - 1) (toString tok)

parseSList :: ByteString → Int → [SExpr] → Either ParseError SExpr
parseSList bs i acc = case bs !? i of
  Nothing → Left $ UnexpectedEOFSList i
  Just c → \cases
    | c == ')' → Right $ SList i (reverse acc)
    | isSpace c → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        Left err → Left err
        Right child → parseSList bs (endPos child + 1) (child : acc)

parseSString :: ByteString → Int → Bool → [Char] → Either ParseError SExpr
parseSString bs i escape acc = case bs !? i of
  Nothing → Left $ UnexpectedEOFSString i
  Just c → case c of
    '"' | not escape → Right $ SString i (reverse acc)
    '\\' | not escape → parseSString bs (i + 1) True acc
    'n' | escape → parseSString bs (i + 1) False ('\n' : acc)
    _ → parseSString bs (i + 1) False (c : acc)
\end{minted}

Now, this implementation is already quite efficient for a strict setting. The functions are as tail-recursive as they can be, and they use indexing and slicing into a bytestring ($\mathcal{O}(1)$ operation) instead of allocating tons of strings on the heap.

That being said, it is possible to obtain very significative performance gains by using destinations with only very little stylistic changes in the code.

Accumulators of tail-recursive functions just have to be changed into destinations. Instead of writing elements into a list that will be reversed at the end as we did before, the program in the destination style will directly write the elements into their final location.

It is good to note that destination allow to reverse the natural order in which a structure is built. For a list, the natural operation in functional programming languages is \emph{prepend}/\emph{cons}, which adds an element at the front of an existing list (bottom-up approach). Thanks to destinations, it's possible to build a list starting from its top element first, and adding new elements at the end of it (\emph{append}/\emph{fillCons}). It's entirely possible to mix both approaches too, as it will be detailed in the API section.

\newcommand{\mnew}[1]{\colorbox{green}{#1}}
\newcommand{\mold}[1]{\colorbox{red}{\sout{#1}}}

\begin{minted}[escapeinside=°°,linenos]{haskell}
parseSExprDS :: ByteString → Int → Dest SExpr ⊸ Either ParseError Int
parseSExprDS bs i d = case bs !? i of
  Nothing → °\mnew{d & fillLeaf defaultSExpr}° `lseq` Left $ UnexpectedEOFSExpr i
  Just c → case c of
    ')' → °\mnew{d & fillLeaf defaultSExpr}° `lseq` Left $ UnexpectedClosingParen i
    '(' → parseSListDS bs (i + 1) °\mnew{(d & fill @'SList)}\mold{[]}°
    '"' → parseSStringDS bs (i + 1) False °\mnew{(d & fill @'SString)}\mold{[]}°
    _ →
      let tok = extractNextToken bs i -- take chars until delimiter/space
        in if null tok
            then -- c is a (leading) space, skip it and recurse
              parseSExprDS bs (i + 1) d
            else case parseInt tok of
              Just int →
                °\mnew{d & fill @'SInteger & fillLeaf int}°
                  `lseq` Right (i + length tok - 1)
              _ →
                °\mnew{d & fill @'SSymbol & fillLeaf (toString tok)}°
                  `lseq` Right (i + length tok - 1)

parseSListDS :: ByteString → Int → Dest [SExpr] ⊸ Either ParseError Int
parseSListDS bs i d = case bs !? i of
  Nothing → °\mnew{d & fill @'[]}° `lseq` Left $ UnexpectedEOFSList i
  Just c →
    \cases
      | c == ')' → °\mnew{d & fill @'[]}° `lseq` Right i°\mold{(reverse acc)}°
      | isSpace c → parseSListDS bs (i + 1) d
      | otherwise →
          let !(dh, dt) = °\mnew{d & fill @'(:)}°
          in case parseSExprDS bs i °\mnew{dh}° of
                Left err → dt & fill @'[] `lseq` Left err
                Right endPos → parseSListDS bs (endPos + 1) °\mnew{dt}\mold{(child : acc)}°

parseSStringDS :: ByteString → Int → Bool → Dest [Char] ⊸ Either ParseError Int
parseSStringDS bs i escape d = case bs !? i of
  Nothing → °\mnew{d & fill @'[]}° `lseq` Left $ UnexpectedEOFSString i
  Just c → case c of
    '"' | not escape → °\mnew{d & fill @'[]}° `lseq` Right i°\mold{(reverse acc)}°
    '\\' | not escape → parseSStringDS bs (i + 1) True d
    'n' | escape →
        let !(dh, dt) = °\mnew{d & fill @'(:)}°
         in °\mnew{dh & fillLeaf '\textbackslash{}n'}° `lseq` parseSStringDS bs (i + 1) False °\mnew{dt}\mold{('\textbackslash{}n' : acc)}°
    _ →
        let !(dh, dt) = °\mnew{d & fill @'(:)}°
         in °\mnew{dh & fillLeaf c}° `lseq` parseSStringDS bs (i + 1) False °\mnew{dt}\mold{(c : acc)}°
\end{minted}


\begin{itemize}
  \item Even for error cases, we are forced to consume the destination that we receive as an argument, hence we write some sensible default data to it (see lines 3, 5, 23 and 36)
  \item Because of the top-down approach, it's necessary to choose which variant of SExpr is being built very early (by writing the corresponding constructor into the \mintinline{haskell}`SExpr` destination), instead of building an accumulator and wrapping the variant constructor over it as it was done in the naive implementation (see lines 6 and 7) ;
  \item The SExpr value resulting from the call of \mintinline{haskell}`parseSExpr` inside \mintinline{haskell}`parseSList` is no longer collected by the caller ; but instead written directly into its final location by the callee (see lines 30 to 32).
  \item Adding an element \mintinline{haskell}`a` to the accumulator \mintinline{haskell}`[a]` is replaced with adding a new cons cell with \mintinline{haskell}`fill @'(:)`, writing the element to the head destination (\mintinline{haskell}`Dest a`), and then continuing the processing with the tail destination (\mintinline{haskell}`Dest [a]`) (see lines 29, 32, 42 and 45).
  \item Instead of reversing and returning the accumulator at the end of the processing, it is enough to complete the list by writing a nil element to the tail destination (with \mintinline{haskell}`fill @'[]`) (see lines 26 and 38).
\end{itemize}

- More efficient GC-wise (see -T benchmark)

- More efficient runtime-wise

\section{Technical development}

\subsection{API Design}

The main design principle behind destination is that no structure can be read before all its destinations have been written to. That way, incomplete data structures can be freely passed around and stored, but need to be completed before any pattern-matching can be made on them.

Hence we introduce a new data type \mintinline{haskell}`Incomplete r a b` where \mintinline{haskell}`a` stands for the type of the structure being built, and \mintinline{haskell}`b` is the type of what needs to be linearly consumed before the structure can be read.

Types aren't linear by themselves in Linear Haskell. Instead, functions can be made linear or not, and linearity of resources are ensured through scope-functions: functions taking a callback that linearly consumes the resource (very much like continuation-passing style).

Let's make things clearer with an example:
\begin{minted}{haskell}
data Resource

withResource :: (Resource ⊸ a) → a
\end{minted}

If \mintinline{haskell}`withResource` is the only producer of \mintinline{haskell}`Resource`, then the only way to ever access a resource will be to supply a linear callback to \mintinline{haskell}`withResource`. Still, this is not enough ; because \mintinline{haskell}`\x → x` is indeed a linear callback, one could use \mintinline{haskell}`withResource (\x → x)` to leak a \mintinline{haskell}`Resource`, and then use it in a non-linear fashion.

We must force the callback to actually consume the resource, and not leak it to the outside. To forbid the resource from appearing anywhere in the return type of the callback, we will ask the return type to be wrapped in \mintinline{haskell}`Ur`. Putting something in \mintinline{haskell}`Ur` is a non-linear operation, except for \mintinline{haskell}`Movable` types, which are basic ones (\mintinline{haskell}`Int`, \mintinline{haskell}`String`, \mintinline{haskell}`Char`...) and structures made of them. As linear resource is simply a data structure which doesn't implement \mintinline{haskell}`Movable`, and which cannot be wrapped linearly in \mintinline{haskell}`Ur`.

With the following declaration, our linear resource cannot leak to the outside world, and must be consumed linearly by the callback (using other functions supplied by the API, written in direct style this time):

\begin{minted}{haskell}
class Movable a where
  move :: a ⊸ Ur a

data Resource

withResource :: (Resource ⊸ Ur a) → Ur a
updateResource :: Int ⊸ Resource ⊸ Resource
closeResource :: Resources ⊸ ()

-- OK
withResource (\r → r & updateResource 42 & closeResource & move) :: Ur ()

-- fails with linearity error
withResource (\r → r & move) :: Ur Resource
\end{minted}

This is mostly the design principle that have been used for destinations in Haskell. In order to access the \mintinline{haskell}`Incomplete`'s \mintinline{haskell}`a` value, the \mintinline{haskell}`b` side must be transformed/consumed into something with type \mintinline{haskell}`Ur c`. Because the \mintinline{haskell}`b` side hosts the destinations initially, they have to be consumed by a linear callback mapping on \mintinline{haskell}`b` side before \mintinline{haskell}`fromReg` can be used to access the \mintinline{haskell}`a`. As we explained above, they cannot leak as there is no linear way to produce a \mintinline{haskell}`Ur Dest` from a \mintinline{haskell}`Dest`.

\begin{minted}{haskell}
newtype Incomplete r a b = Incomplete (a, b)

instance Control.Functor (Incomplete r a) where
  fmap :: (b ⊸ c) ⊸ Incomplete r a b ⊸ Incomplete r b c
  fmap f (Incomplete (s, d)) = Incomplete (s, f d)

fromRegExtract :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a (Ur b) ⊸ Ur (a, b)
\end{minted}

\mintinline{haskell}`Region`, \mintinline{haskell}`RegionContext r` and \mintinline{haskell}`RegionToken r` are mostly implementation noise for the API. There presence will be justified in the next subsection.

Allocation a new receiver of type \mintinline{haskell}`a` is done through \mintinline{haskell}`alloc`:

\begin{minted}{haskell}
alloc :: ∀ r a. RegionToken r ⊸ Incomplete r a (Dest r a)
\end{minted}

This function signature can be read that way : it consumes a region token, and returns an object holder, which upon consumption of a \mintinline{haskell}`Dest r a`, will unlock the object of type \mintinline{haskell}`a`. At this point, the return value of `alloc` is pretty much the identity: give it an \mintinline{haskell}`a` (to fill the \mintinline{haskell}`Dest r a`), and it will return an \mintinline{haskell}`a`.

To fill that hole represented by \mintinline{haskell}`Dest r a`, several functions are available:

\begin{itemize}
  \item \mintinline{haskell}`fillLeaf :: ∀ r a. (RegionContext r) ⇒ a → Dest r a ⊸ ()` \\will use a non-linear value of type \mintinline{haskell}`a` to fill the hole ;
  \item \mintinline{haskell}`fillComp :: ∀ r a b. (RegionContext r) ⇒ Incomplete r a b ⊸ Dest r a ⊸ b` \\will use an incomplete object of type \mintinline{haskell}`a` to fill the hole ; and the resulting holes for the bigger structure will be the ones of that object. In other terms, \mintinline{haskell}`fillComp` composes two structures with holes together ;
  \item \mintinline{haskell}`fill :: ∀ liftedCtor r a. Dest r a ⊸ DestsOf liftedCtor r a` \\takes a constructor as a type parameter (\mintinline{haskell}`liftedCtor`) and will write a shallow instance of that constructor into the \mintinline{haskell}`Dest r a`, returning the destinations corresponding to that constructor's fields.\\ For example, \mintinline{haskell}`fill @Just @r @(Maybe Int) :: Dest r (Maybe Int) ⊸ Dest r Int` writes a shallow \mintinline{haskell}`Just` constructor in the \mintinline{haskell}`Maybe Int` hole, and returns the \mintinline{haskell}`Dest Int` corresponding to the hole of type \mintinline{haskell}`Int` that still needs to be filled.
\end{itemize}

\mintinline{haskell}`fill` is probably the most interesting of the three, and will be the most used one too, because it enables the user to build data structures in a top-down approach, which complements very well the natural bottom-up way of constructing data structures in functional programming languages. Thanks to destinations, the user can now choose between those two approaches and pick the most efficient or more natural way for the problem at hand.

\mintinline{haskell}`fillComp` offers a way to mix both approaches: one can build small chunks in a top-down approach, and combine them together in a bottom-up fashion even if they aren't all complete.

\mintinline{haskell}`fillLeaf` is just a restriction of \mintinline{haskell}`fillComp`. It is used very frequently for types whose constructors aren't \mintinline{haskell}`Fill`able because they wrap over unpacked or primitive fields.

\subsection{Note about Compact Regions}

At the moment, destination-style programming is only possible in compact regions. Compact regions are special chunks on the heap that will only be very lightly inspected by the garbage collector, and thanks to that, we can do chirurgical memory updates in those without being afraid that it will interfere with garbage collection (especially move operations).

Because we have immobile chunks of memory, destinations can be implemented as a wrapper over a raw pointer which points to the memory location where data have to be written:

\begin{minted}{haskell}
data Dest r a = Dest Addr#
\end{minted}

The phantom type parameter \mintinline{haskell}`r` that is present everywhere in the API ensures that objects can only interact with other ones from the same region (as outgoing pointers across different regions are not allowed by design of Compact regions).

\subsection{User-land haskell implementation details}
 
(Maybe merge with previous subsection)

- Need for indirection (because of composition)

- How to make fillLeaf based on fillComp but without too much overhead

- Efficiently implement fromReg and fromRegExtract

- How fill works and is derived via Generics

\subsection{Changes to GHC's internals and RTS}

- Story about getting the info table ptr or a given constructor (blogpost)

- How to allocate a shallow constructor

- Note about how to emulate that with gShallowCtor and "raw memory" runtime reflection when not using a custom GHC version

\section{Evaluating performance of destination-style programming}

\subsection{Benchmarking / profiling strategy}

- Three modes (-T, -s, -p)

- How to evaluate naive code (why we use both copyIntoReg and force)

\subsection{Performance of map implementation (in a strict context)}

- How this is important for Ocaml

\subsection{Performance of the SExpr parser}

\subsection{Performance of BFS Tree traversal}

\subsection{Qualitative evaluation of destination code VS naive code}

- TODO: implement a naive implement of functional mapMBFS

\section{Conclusion and related work}

- Why it's an improvement over Minamide

- Lifting the non-linear restriction for elements stored in dest-allocated structures (= requires more theoretical work)

- Using destinations in different contexts than compact regions (normal GC heap, other kinds of chunk-allocated memory)

\printbibliography

\end{document}
